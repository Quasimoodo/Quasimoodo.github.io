{"meta":{"version":1,"warehouse":"4.0.1"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-next/source/images/2.jpg","path":"images/2.jpg","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/css/noscript.styl","path":"css/noscript.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/logo-algolia-nebula-blue-full.svg","path":"images/logo-algolia-nebula-blue-full.svg","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/mine-32x32.png","path":"images/mine-32x32.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/mine-16x16.png","path":"images/mine-16x16.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/images/taffy.png","path":"images/taffy.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/comments-buttons.js","path":"js/comments-buttons.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/comments.js","path":"js/comments.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/config.js","path":"js/config.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/pjax.js","path":"js/pjax.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/schedule.js","path":"js/schedule.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/fancybox.js","path":"js/third-party/fancybox.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/pace.js","path":"js/third-party/pace.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/quicklink.js","path":"js/third-party/quicklink.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/rating.js","path":"js/third-party/rating.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/gitter.js","path":"js/third-party/chat/gitter.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/chatra.js","path":"js/third-party/chat/chatra.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/baidu-analytics.js","path":"js/third-party/analytics/baidu-analytics.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/tidio.js","path":"js/third-party/chat/tidio.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/changyan.js","path":"js/third-party/comments/changyan.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/google-analytics.js","path":"js/third-party/analytics/google-analytics.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/growingio.js","path":"js/third-party/analytics/growingio.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqus.js","path":"js/third-party/comments/disqus.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqusjs.js","path":"js/third-party/comments/disqusjs.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/gitalk.js","path":"js/third-party/comments/gitalk.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/isso.js","path":"js/third-party/comments/isso.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/livere.js","path":"js/third-party/comments/livere.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/katex.js","path":"js/third-party/math/katex.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/mathjax.js","path":"js/third-party/math/mathjax.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/utterances.js","path":"js/third-party/comments/utterances.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/algolia-search.js","path":"js/third-party/search/algolia-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/local-search.js","path":"js/third-party/search/local-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/firestore.js","path":"js/third-party/statistics/firestore.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/mermaid.js","path":"js/third-party/tags/mermaid.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/lean-analytics.js","path":"js/third-party/statistics/lean-analytics.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/pdf.js","path":"js/third-party/tags/pdf.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/About-Moby-Dick.md","hash":"389704bcc22556e0fab36b6ecba361c895408e56","modified":1655723769616},{"_id":"source/_posts/testpic.md","hash":"558b240a137a1ed7af8d894c8014fb603c503dd9","modified":1655723769626},{"_id":"source/_posts/Philip-Larkin.md","hash":"0c3a04082592692e02a8e19dbd671400b9d4fd42","modified":1655725315092},{"_id":"source/_posts/SPT-Code.md","hash":"ca256b0d0476d2b3b8e9cc05ab172aa136403cbb","modified":1655730887373},{"_id":"source/_posts/火柴.md","hash":"c9636e5142f1d010b7b900855e2a975280f845fd","modified":1655723769630},{"_id":"source/categories/index.md","hash":"3123f55189718134e31eb51d72ddd9e68ecd4a18","modified":1655723769631},{"_id":"source/tags/index.md","hash":"1c3722c4b4af5a2ea8970da1bfec9b8c68159367","modified":1655723769632},{"_id":"source/about/index.md","hash":"52d246b19a283f0a9f8e9005bdd53115444b21ed","modified":1655723769631},{"_id":"source/_posts/SPT-Code/image-20220527231806850.png","hash":"bdd3bb79709080c4bb8493ae66cd290e7b8b8237","modified":1655723769621},{"_id":"source/_posts/SPT-Code/image-20220527233143119.png","hash":"d089096a54c50ed0ab12ae4dacbe4a85b2bcb6bc","modified":1655723769625},{"_id":"source/_posts/SPT-Code/image-20220527233752649.png","hash":"add232d275639723c148095061934b6857daf254","modified":1655723769626},{"_id":"source/_posts/testpic/image-20220523211852621.png","hash":"f443eb7116b28a70a135256d0d4521e3710e45ff","modified":1655723769627},{"_id":"source/_posts/SPT-Code/image-20220527230530594.png","hash":"ca5795fe19159888c5a97acb4f35f489db7ab7ed","modified":1655723769620},{"_id":"source/_posts/SPT-Code/image-20220527232629535.png","hash":"22e81124540e148c61cb00bc3e3f986c71713087","modified":1655723769624},{"_id":"source/_posts/testpic/image-20220524021029166.png","hash":"a4f4e62846dc739c9d970f5eea1b4414740f2184","modified":1655723769630},{"_id":"node_modules/hexo-theme-next/README.md","hash":"56638e4978154a2f2a3f03ba84047b77b4a499cc","modified":1655723668106},{"_id":"node_modules/hexo-theme-next/LICENSE.md","hash":"68fc9a03d50fd4b5ea97092b05967d1819dea2c4","modified":1655723668102},{"_id":"node_modules/hexo-theme-next/_vendors.yml","hash":"8c2886a6af624f04fc6a376daf48c0698ea71bf7","modified":1655723668674},{"_id":"node_modules/hexo-theme-next/_config.yml","hash":"916bd29a95250cb1fb778d88f6b1864f5db26c3e","modified":1655730246258},{"_id":"node_modules/hexo-theme-next/package.json","hash":"b32be32269dd2e241790a766a60357bfe13f2d45","modified":1655723668096},{"_id":"node_modules/hexo-theme-next/docs/AUTHORS.md","hash":"a648823121563c34a177ae91f5a774b5e29f01a0","modified":1655723668098},{"_id":"node_modules/hexo-theme-next/docs/LICENSE.txt","hash":"f5b14f791b7cfa1d16da981d929152e088a5d1b8","modified":1655723668671},{"_id":"node_modules/hexo-theme-next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1655723668097},{"_id":"node_modules/hexo-theme-next/languages/bn.yml","hash":"fccbf2855392186e11daa8590121073594037b7b","modified":1655723668676},{"_id":"node_modules/hexo-theme-next/languages/ar.yml","hash":"bca66db21c015dbd32970d8708b898518a773e1e","modified":1655723668675},{"_id":"node_modules/hexo-theme-next/languages/de.yml","hash":"4be7b8b76c81bf1853eb36d2e874b17546a0e792","modified":1655723668677},{"_id":"node_modules/hexo-theme-next/languages/README.md","hash":"b2567e32805dda79601157351a07e5ca9fe01315","modified":1655723668105},{"_id":"node_modules/hexo-theme-next/languages/es.yml","hash":"b813da5aed9d73b809133db4dfb08f90ec56afd9","modified":1655723668680},{"_id":"node_modules/hexo-theme-next/languages/fa.yml","hash":"6456d40dd42f44101d9d6e7054e9884e9163f948","modified":1655723668681},{"_id":"node_modules/hexo-theme-next/languages/en.yml","hash":"814d81c27fed736055ee300e0a6505b26ff4313c","modified":1655723668679},{"_id":"node_modules/hexo-theme-next/languages/fr.yml","hash":"b15dc05afdc94de02e5d3fee4f8d3dc5594dd37e","modified":1655723668682},{"_id":"node_modules/hexo-theme-next/languages/id.yml","hash":"14e794db4eca36b257994d81eb513e61d1edcbd6","modified":1655723668683},{"_id":"node_modules/hexo-theme-next/languages/ko.yml","hash":"819c19eb9d142e5411f77cf3821d90f740ee114a","modified":1655723668685},{"_id":"node_modules/hexo-theme-next/languages/pt-BR.yml","hash":"a1f27b3a592fc58f17d247f5563ff4a90a3da5f2","modified":1655723668687},{"_id":"node_modules/hexo-theme-next/languages/it.yml","hash":"c1eeab4992c76bfd436bb205ce58b1cfeef55ee6","modified":1655723668684},{"_id":"node_modules/hexo-theme-next/languages/ja.yml","hash":"d48c4157e0e02e847aac7b513580d3364c81948c","modified":1655723668685},{"_id":"node_modules/hexo-theme-next/languages/si.yml","hash":"615d18d044f44df476d6bfbf73f7b0edc2632168","modified":1655723668689},{"_id":"node_modules/hexo-theme-next/languages/nl.yml","hash":"ecb8e39c6225f3c068a5fdd569ee7dafd5c41a1f","modified":1655723668686},{"_id":"node_modules/hexo-theme-next/languages/pt.yml","hash":"63a3e1e728ba5e6e22150de7331bb8a654f34960","modified":1655723668688},{"_id":"node_modules/hexo-theme-next/languages/ru.yml","hash":"8c2b6361f2de17561c1a3eede2bf47b4e2ba6ce5","modified":1655723668688},{"_id":"node_modules/hexo-theme-next/languages/tk.yml","hash":"519239e35c3bda7b62b00ff5d34644f45b16fe6a","modified":1655723668692},{"_id":"node_modules/hexo-theme-next/languages/tr.yml","hash":"0bebba73d6f06c7dad61f80c0d7ad5f6f1791a01","modified":1655723668693},{"_id":"node_modules/hexo-theme-next/languages/uk.yml","hash":"7dd24580c0865c5a7bc4d391855045366a598936","modified":1655723668693},{"_id":"node_modules/hexo-theme-next/languages/vi.yml","hash":"c669c34da544a563ceae3e196addc9df6a78e024","modified":1655723668695},{"_id":"node_modules/hexo-theme-next/languages/zh-HK.yml","hash":"f195bb0502ffe66e850077a1af1033455ea65f93","modified":1655723668696},{"_id":"node_modules/hexo-theme-next/languages/zh-CN.yml","hash":"5a3ab21210304efef736e96bad254f789f42c567","modified":1655723668695},{"_id":"node_modules/hexo-theme-next/languages/zh-TW.yml","hash":"92256b90028de9a1e79c6bc0e5885b93e7fb4b17","modified":1655723668697},{"_id":"node_modules/hexo-theme-next/layout/_layout.njk","hash":"20e4160cd0deb4fa272cc3aed0f43520b3cf4a9c","modified":1655723668107},{"_id":"node_modules/hexo-theme-next/layout/archive.njk","hash":"d759f4d2cf5ddc6875ea250113a00662c1caf6d1","modified":1655723668110},{"_id":"node_modules/hexo-theme-next/layout/index.njk","hash":"dd63e488ae8cc144335a5958acedf6a16edd7a92","modified":1655723668476},{"_id":"node_modules/hexo-theme-next/layout/tag.njk","hash":"9e16ba20c28a7f2c6bc75aa427f48122301a30aa","modified":1655723668497},{"_id":"node_modules/hexo-theme-next/layout/page.njk","hash":"6c40aa438c658eb7f0cd0f6a759f18b43e7e8f93","modified":1655723668485},{"_id":"node_modules/hexo-theme-next/layout/category.njk","hash":"c68b7343d0f8145010f93351908cc36ef6212ec1","modified":1655723668120},{"_id":"node_modules/hexo-theme-next/layout/post.njk","hash":"6abeb85fb3e4c382ed4bb6049b12a807e6226e67","modified":1655723668493},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"7a06d443f374bd1e84294067a0ac796afd9fbe60","modified":1655723668101},{"_id":"node_modules/hexo-theme-next/layout/_macro/post-collapse.njk","hash":"1a30d751871dabfa80940042ddb1f77d07d830b9","modified":1655723668487},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/README.md","hash":"ccf27b9249524b9fec1c15497b4353c8d1748c6c","modified":1655723668104},{"_id":"node_modules/hexo-theme-next/docs/ru/README.md","hash":"6c82bfd2ec8248c248da701f091b548a7a133580","modified":1655723668103},{"_id":"node_modules/hexo-theme-next/docs/zh-CN/CONTRIBUTING.md","hash":"a089f7a8368ab0b7d7b9b7ec0ac3767a453435df","modified":1655723668101},{"_id":"node_modules/hexo-theme-next/layout/_partials/footer.njk","hash":"cfb7001c7766a50eba23c990179343cdc42b23ae","modified":1655726418385},{"_id":"node_modules/hexo-theme-next/layout/_partials/comments.njk","hash":"d0c470b0f6690aa217e9ada848c5e2e73fb27c6f","modified":1655723668124},{"_id":"node_modules/hexo-theme-next/layout/_partials/languages.njk","hash":"e43f22198cccb5f6e306b1ce0d28d12a4fb891f8","modified":1655723668478},{"_id":"node_modules/hexo-theme-next/layout/_macro/sidebar.njk","hash":"eb786e8b35e354287cda345c524cd35ec955f692","modified":1655723668495},{"_id":"node_modules/hexo-theme-next/layout/_scripts/index.njk","hash":"6668878a0f9a1166c6a879755f54a08d942da870","modified":1655723668472},{"_id":"node_modules/hexo-theme-next/layout/_partials/widgets.njk","hash":"852a750524decf1efa587cd52b09e387ed8315de","modified":1655723668502},{"_id":"node_modules/hexo-theme-next/layout/_macro/post.njk","hash":"434b3e76a040a816169e1929657e4176e7b8164c","modified":1655723668492},{"_id":"node_modules/hexo-theme-next/layout/_partials/pagination.njk","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1655723668486},{"_id":"node_modules/hexo-theme-next/layout/_scripts/vendors.njk","hash":"be80b9fe415a9a09d74c28e230995fd292dfc123","modified":1655723668501},{"_id":"node_modules/hexo-theme-next/layout/_third-party/pace.njk","hash":"d7ad5714079f7f65446f880baf14722435ca9061","modified":1655723668483},{"_id":"node_modules/hexo-theme-next/scripts/events/index.js","hash":"3ce10d4cce94e3d4c482c2e18bb6f0f0ca380d3d","modified":1655723667992},{"_id":"node_modules/hexo-theme-next/layout/_third-party/rating.njk","hash":"1bcdbc7fde26d6d9ef4e7fa43ffcff5a9506b20e","modified":1655723668494},{"_id":"node_modules/hexo-theme-next/layout/_third-party/index.njk","hash":"d41eeb262978e34de4679d8971a9e7ac5d90ecbc","modified":1655723668474},{"_id":"node_modules/hexo-theme-next/layout/_third-party/fancybox.njk","hash":"844559f46e2ff1c8be234d5763703106e2072a7b","modified":1655723668127},{"_id":"node_modules/hexo-theme-next/scripts/filters/default-injects.js","hash":"872f01cb10e422a648ea505436532e776e92926b","modified":1655723667977},{"_id":"node_modules/hexo-theme-next/scripts/filters/locals.js","hash":"9eb5310664759931287dd28ea39165dfb67f12ed","modified":1655723668000},{"_id":"node_modules/hexo-theme-next/scripts/filters/minify.js","hash":"f160e39943e39d7276da86adb47c3f08e5f22c7a","modified":1655723668004},{"_id":"node_modules/hexo-theme-next/scripts/filters/post.js","hash":"30e03a1d4828259f82d46e64cbfe2955b6cff9a9","modified":1655723668014},{"_id":"node_modules/hexo-theme-next/scripts/helpers/engine.js","hash":"d292b78485e8e8055712b0ed6de7cf559c5fbdcd","modified":1655723667982},{"_id":"node_modules/hexo-theme-next/scripts/helpers/font.js","hash":"3394185a7f0393c16ce52c8028f90da3e9239c55","modified":1655723667986},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-url.js","hash":"a11b71ba0c5012e2cdcab31c15439156b215563e","modified":1655723668009},{"_id":"node_modules/hexo-theme-next/scripts/helpers/navigation.js","hash":"78107021101553c3d23e89290f7530b60cf4aa86","modified":1655723668007},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-config.js","hash":"226fccbe9c93265e65a300e3cb4bf6f9065cfdd7","modified":1655723668008},{"_id":"node_modules/hexo-theme-next/scripts/tags/button.js","hash":"c6ad2ed544fbb25ecb5d820c36e76302504271b7","modified":1655723667957},{"_id":"node_modules/hexo-theme-next/scripts/helpers/next-vendors.js","hash":"afdd6a188a74c188f0dd154fac70efd4080ca262","modified":1655723668010},{"_id":"node_modules/hexo-theme-next/scripts/tags/caniuse.js","hash":"935a311142a409c1896b3ae3f01fe7a9e2db1134","modified":1655723667958},{"_id":"node_modules/hexo-theme-next/scripts/tags/center-quote.js","hash":"92c19d796bdb3320df9caea59bf52df7a95d9da9","modified":1655723667958},{"_id":"node_modules/hexo-theme-next/scripts/tags/index.js","hash":"17f9451ce1f10f78437f52218757d38d4e1591b0","modified":1655723667993},{"_id":"node_modules/hexo-theme-next/scripts/tags/group-pictures.js","hash":"9ed799c329abf830f623689d7e136991256a24ca","modified":1655723667989},{"_id":"node_modules/hexo-theme-next/scripts/tags/label.js","hash":"8a73348186113bae0a51ea2f891c1bb882fab05a","modified":1655723667996},{"_id":"node_modules/hexo-theme-next/scripts/tags/mermaid.js","hash":"4fb01ca650fa8b256b8d48f50dc1b18350bd3d6d","modified":1655723668002},{"_id":"node_modules/hexo-theme-next/scripts/tags/note.js","hash":"7b94ddb46b7d4b0fe815f2fbe4bd375f07f55363","modified":1655723668010},{"_id":"node_modules/hexo-theme-next/scripts/tags/link-grid.js","hash":"18a483c2d5afd701f6080ffdddf2d1321370336c","modified":1655723667998},{"_id":"node_modules/hexo-theme-next/scripts/tags/pdf.js","hash":"344636b6fd7e27e8831c1e194039afc0d61931cd","modified":1655723668012},{"_id":"node_modules/hexo-theme-next/scripts/tags/video.js","hash":"2ee926448583be8f95af1f2884ae2c9c4830151d","modified":1655723668095},{"_id":"node_modules/hexo-theme-next/scripts/tags/tabs.js","hash":"0eabe51da40b4b13e16419c8fe02452d9a4fef73","modified":1655723668017},{"_id":"node_modules/hexo-theme-next/source/css/_colors.styl","hash":"3c6798c10cc220d83481cb3f3782e78558cee789","modified":1655723668505},{"_id":"node_modules/hexo-theme-next/source/css/_mixins.styl","hash":"32d31cb5a155681c19f5ad0bb56dcb08429f93ef","modified":1655723668514},{"_id":"node_modules/hexo-theme-next/source/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1655723667951},{"_id":"node_modules/hexo-theme-next/layout/_third-party/quicklink.njk","hash":"0efed71ed530447718c4ea5bbd5fc8695b0b0d5f","modified":1655723668493},{"_id":"node_modules/hexo-theme-next/source/css/noscript.styl","hash":"263eddabfae40e54c0591e7baa8403ade8cdd56d","modified":1655723668645},{"_id":"node_modules/hexo-theme-next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1655723668502},{"_id":"node_modules/hexo-theme-next/source/images/logo.svg","hash":"2cb74fd3ea2635e015eabc58a8d488aed6cf6417","modified":1655723668670},{"_id":"node_modules/hexo-theme-next/source/css/main.styl","hash":"78ce791cc4ac95386cf6839ca72f5f7b51f86ee9","modified":1655723668639},{"_id":"node_modules/hexo-theme-next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1655723668504},{"_id":"node_modules/hexo-theme-next/source/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1655723668670},{"_id":"node_modules/hexo-theme-next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1655723668503},{"_id":"node_modules/hexo-theme-next/source/images/mine-32x32.png","hash":"13e8c0230b242bc68c3b54267ef0024d7fb11667","modified":1653934034102},{"_id":"node_modules/hexo-theme-next/source/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1655723667956},{"_id":"node_modules/hexo-theme-next/source/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1655723667965},{"_id":"node_modules/hexo-theme-next/source/images/mine-16x16.png","hash":"46a56b8ee580a508fedfceff822c9dc8be0fa20d","modified":1653934034099},{"_id":"node_modules/hexo-theme-next/source/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1655723667966},{"_id":"node_modules/hexo-theme-next/source/js/next-boot.js","hash":"da0f07f9eaaa83de70128b0feaea3fdadb90457a","modified":1655723668007},{"_id":"node_modules/hexo-theme-next/source/js/motion.js","hash":"f7c825cbff11885fa0dffa64824fd00e505d6a8d","modified":1655723668004},{"_id":"node_modules/hexo-theme-next/source/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1655723667970},{"_id":"node_modules/hexo-theme-next/source/js/pjax.js","hash":"919f5281c4a04d11cfd94573ecf57b3dbabd3cc8","modified":1655723668014},{"_id":"node_modules/hexo-theme-next/source/js/schedule.js","hash":"a1333258726caf84f368a8f8454639c7dc1626bb","modified":1655723668016},{"_id":"node_modules/hexo-theme-next/layout/_partials/head/head-unique.njk","hash":"8da52a144060db1a0a088ccb2e6cc8376d1fce70","modified":1655723668468},{"_id":"node_modules/hexo-theme-next/source/js/utils.js","hash":"200088bfd042f5304b2a04befab0829148845e0e","modified":1655723668092},{"_id":"node_modules/hexo-theme-next/layout/_partials/head/head.njk","hash":"0ba2bf0266f1fcb8edbd961869f8521b29685c56","modified":1655723668469},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/brand.njk","hash":"aff4613756456be26415febc668860fdab8d33c5","modified":1655723668114},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/index.njk","hash":"650de421a8ce4cf685428ffbe0087ff84cbd1356","modified":1655723668470},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/menu.njk","hash":"ee6fc2f111572d3eeab0a2fecbb2d6b3e37ab26b","modified":1655723668481},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/menu-item.njk","hash":"41a8b0cc16f60fa085cb719d07216d86b6bc4bf8","modified":1655723668481},{"_id":"node_modules/hexo-theme-next/layout/_partials/header/sub-menu.njk","hash":"06480d8ec5f0b87eafd47f082f07968d7282dd5c","modified":1655723668497},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/breadcrumb.njk","hash":"89825e75cc45e9709fa6ba89883669eedaff6f46","modified":1655723668116},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/page-header.njk","hash":"7ed4f102a1825195cff8d7995bf9219f323a9034","modified":1655723668484},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/schedule.njk","hash":"0f4bc8e257da60f77c0c1738607b2bde55810684","modified":1655723668494},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/categories.njk","hash":"17156d99941f28a225951ffdcfa9a115e20dc2d2","modified":1655723668118},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-footer.njk","hash":"bde2c7356d9362972bde41cc206d5816f8ed714d","modified":1655723668489},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-copyright.njk","hash":"133942922e34abae9e4de7ea5591d77c0caa4b37","modified":1655723668488},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-followme.njk","hash":"154df0bb323c332d8c25343f258ee865e5553423","modified":1655723668489},{"_id":"node_modules/hexo-theme-next/layout/_partials/page/tags.njk","hash":"a18d1598e36cc72f2b0b24c3cc3c5990dfaa3254","modified":1655723668498},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-meta.njk","hash":"9fa47e4fb342811da590ee4adc91cf81118c0a39","modified":1655723668490},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-related.njk","hash":"57eca76cfbbe9a65bc2a77f1deebf003ed335673","modified":1655723668491},{"_id":"node_modules/hexo-theme-next/layout/_partials/post/post-reward.njk","hash":"002b51d0cae3f2e2e008bdc58be90c728282de5b","modified":1655723668492},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/algolia-search.njk","hash":"efb2b6f19df02ba5ae623a1f274fff52aed21e6f","modified":1655723668108},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/index.njk","hash":"8f6f256ab3b351ffc80f1f3f1d9834e9a7cfac31","modified":1655723668471},{"_id":"node_modules/hexo-theme-next/layout/_partials/search/localsearch.njk","hash":"661f7acae43f0be694266323320f977d84119abe","modified":1655723668479},{"_id":"node_modules/hexo-theme-next/layout/_partials/sidebar/site-overview.njk","hash":"3d8591bb92df77ceb9d5b07bc76da1ca89e5bd76","modified":1655723668496},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/cloudflare.njk","hash":"a5b8297c2c383124dd6a56e256ecc0c0dcf489be","modified":1655723668123},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/baidu-analytics.njk","hash":"6215309aee028dcb734452beec448c5afb6c63fc","modified":1655723668113},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/growingio.njk","hash":"8afaa772c390bd9d53a5cff9645ac3168334eb98","modified":1655723668466},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/google-analytics.njk","hash":"d89066ff53879693f023e540d59c86137172c529","modified":1655723668131},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/index.njk","hash":"45477a04cf2b3c077061c8c3ada216c1ae288e0e","modified":1655723668473},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/chatra.njk","hash":"d7263fca16d0278ccf1f6aa1c6df6902a6344a09","modified":1655723668122},{"_id":"node_modules/hexo-theme-next/layout/_third-party/analytics/microsoft-clarity.njk","hash":"9dc00fcb0a05899f048eace9f9160b78956655d5","modified":1655723668483},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/gitter.njk","hash":"f8cc14b7aa949999a1faaeb7855e2f20b59a386d","modified":1655723668130},{"_id":"node_modules/hexo-theme-next/layout/_third-party/chat/tidio.njk","hash":"02aab857c27fc103216029be991688b12a73a525","modified":1655723668498},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/disqus.njk","hash":"9375b19a89b7fa9474e558d085af5448d4c5c50c","modified":1655723668125},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/changyan.njk","hash":"d1c950f8fbdf85e7a3eae5463767a89e858e8220","modified":1655723668121},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/disqusjs.njk","hash":"0749cb6902baecdfd01f779a2a2513f6d2f6a823","modified":1655723668126},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/gitalk.njk","hash":"b63b7e2ede0d3e66e732fa1a06bda9b19e1e85d4","modified":1655723668130},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/index.njk","hash":"abf37fc55aa86702118e8fdf5bf2d389dd589aa0","modified":1655723668475},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/utterances.njk","hash":"5a94032bc3512a10ad4328fc19ec07b819a1d687","modified":1655723668499},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/isso.njk","hash":"64cc3bdaf644fd32c0d0a247f29f5b6904da9af3","modified":1655723668476},{"_id":"node_modules/hexo-theme-next/layout/_third-party/comments/livere.njk","hash":"3b13b09fba84ec6000886890a6710736a2b8fafe","modified":1655723668479},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/katex.njk","hash":"d82c24136bbd3443b85f07f5579845833b594684","modified":1655723668477},{"_id":"node_modules/hexo-theme-next/layout/_third-party/math/mathjax.njk","hash":"3677017fd4572b158311f5f5d870590ab25184e0","modified":1655723668480},{"_id":"node_modules/hexo-theme-next/layout/_third-party/search/algolia-search.njk","hash":"24ed76e0c72a25ac152820c750a05826a706b6f4","modified":1655723668109},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/busuanzi-counter.njk","hash":"a4bc501da0f22f7e420f0ca47e83988ce90b1368","modified":1655723668117},{"_id":"node_modules/hexo-theme-next/layout/_third-party/search/localsearch.njk","hash":"e45ea3542cdc9ed7ec8447b5e6f35df4c5e82758","modified":1655723668480},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/firestore.njk","hash":"d32ebe94560fa95824478ebbff531bffc47b194d","modified":1655723668128},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/lean-analytics.njk","hash":"2446e748cdc102c78492216319ac02148db7daf6","modified":1655723668478},{"_id":"node_modules/hexo-theme-next/layout/_third-party/statistics/index.njk","hash":"568ddf7955d11d93fb5e842b403a7ac8b1b7fdb1","modified":1655723668475},{"_id":"node_modules/hexo-theme-next/layout/_third-party/tags/mermaid.njk","hash":"099e031f52fb8e47b3af5b2684737efc9e643ee7","modified":1655723668482},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/config.js","hash":"c8b59b404f5d2a0b3b5cd1a6c9a10af5f30e43b5","modified":1655723667969},{"_id":"node_modules/hexo-theme-next/layout/_third-party/tags/pdf.njk","hash":"2c81984cc4f5123103460442f6e046f5b6c97127","modified":1655723668487},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/highlight.js","hash":"6aec7b2c38c50989a23bfaa0d560e75c7f553e12","modified":1655723667991},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/navigation.js","hash":"dd3562686d95a50375e6fd32e717ccb0d99c1e3d","modified":1655723668006},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/changyan.js","hash":"7fa8701c86485b2fe7324e017101a32417902397","modified":1655723667960},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/common.js","hash":"19a402a225c31edffc50f202a14e0d582d3db23e","modified":1655723667966},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/default-config.js","hash":"93ee5f9109dad885dc38c49bcee630c10f9dce6e","modified":1655723667973},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/disqus.js","hash":"7f71d6b271ba65ff333d5682e7575711d368c0d2","modified":1655723667978},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/disqusjs.js","hash":"135b87d151055eefdbc711d9e704b112b3214a84","modified":1655723667980},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/isso.js","hash":"ff8b5b5145220a17d0ecd9508ba9bd2d3b2da47d","modified":1655723667994},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/gitalk.js","hash":"7bb7dafdd7f6bca8464b54e17e552ce7f1714195","modified":1655723667986},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/utterances.js","hash":"d3bded697bc32dace689d2a6dfb6eb7514169d15","modified":1655723668093},{"_id":"node_modules/hexo-theme-next/scripts/filters/comment/livere.js","hash":"5a07d8bb52bc1d51a624ca8db54be144566c306b","modified":1655723667998},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Gemini.styl","hash":"96e0a7c2a65ce68215e17e369085b2ea2f1334f2","modified":1655723668619},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Mist.styl","hash":"e1fbf169b9b6a194b518240cbd06ec3c48b83d61","modified":1655723668642},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Muse.styl","hash":"e3be898f5ebcf435a26542653a9297ff2c71aeb0","modified":1655723668643},{"_id":"node_modules/hexo-theme-next/source/css/_variables/base.styl","hash":"163c7441d777bee87042d475e6ce0fde199add28","modified":1655723668609},{"_id":"node_modules/hexo-theme-next/source/css/_variables/Pisces.styl","hash":"c65536a128b9bc9dbe2fbb1b235a3cded2891002","modified":1655723668647},{"_id":"node_modules/hexo-theme-next/source/js/schemes/muse.js","hash":"9794bd4fc6a458322949d6a0ade89cd1026bc69f","modified":1655723668005},{"_id":"node_modules/hexo-theme-next/source/js/third-party/fancybox.js","hash":"c098d14e65dd170537134358d4b8359ad0539c2c","modified":1655723667983},{"_id":"node_modules/hexo-theme-next/source/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1655723668011},{"_id":"node_modules/hexo-theme-next/source/js/third-party/quicklink.js","hash":"eed02e6fced8e5a653077205d4d4d7834ca71472","modified":1655723668015},{"_id":"node_modules/hexo-theme-next/source/js/third-party/rating.js","hash":"4e92c2d107ba47b47826829f9668030d5ea9bfb8","modified":1655723668016},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/injects.js","hash":"d987709267a1bc6e5014411e9983d7c49c102c16","modified":1655723667994},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/vendors.js","hash":"64e4024376b51fe81be7ad80235abdf0a83853bd","modified":1655723668094},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/index.styl","hash":"fe1868f47681e00a33a96199302be85377282f63","modified":1655723668624},{"_id":"node_modules/hexo-theme-next/scripts/events/lib/utils.js","hash":"ec996d0673f766167c86df0966e9da1ae036e103","modified":1655723668019},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/back-to-top.styl","hash":"bab653bcf226311381e8411a0492202f1bf1fce9","modified":1655723668606},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/index.styl","hash":"8e34df131830d4fa3725e4590a672ba1cf1903e5","modified":1655723668630},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/reading-progress.styl","hash":"90a86045a33c1bae49fc2f6fa1e1b53170c7f77b","modified":1655723668657},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/mobile.styl","hash":"64775c729512b30b144ab5ae9dc4a4dfd4e13f35","modified":1655723668642},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/base.styl","hash":"d0a7c99095f490b0d2ed6b1be43d435960798cec","modified":1655723668608},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/buttons.styl","hash":"a042571d85ff7265f799004239a45f36b716b8a6","modified":1655723668614},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/comments.styl","hash":"e4fecc889ba3317a64e9abba5842c79dff9b7827","modified":1655723668615},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/index.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1655723668633},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1655723668644},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/toggles.styl","hash":"572a41499391677d84b16d8dbd6a996a3d5ce041","modified":1655723668669},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/pagination.styl","hash":"b5c7782368889fa9fd93807d28ff2daf270e3703","modified":1655723668646},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_layout.styl","hash":"5604ac1e161099a4d3e5657d53507268866dc717","modified":1655723668510},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Gemini/index.styl","hash":"fd49b521d67eaccc629f77b4e095cb7310327565","modified":1655723668635},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_header.styl","hash":"4817e77577896ab5c0da434549917ee703a3f4cf","modified":1655723668507},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_menu.styl","hash":"fb550935d374e0bdf1097fce187337dc05cad3e1","modified":1655723668512},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/_posts-expand.styl","hash":"be6cf377ae8f4a01ee76f9b3014e74161d4d5d17","modified":1655723668514},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_header.styl","hash":"78406b8400abd5d4c670a11d7fa1b8b3cdeccad7","modified":1655730600802},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Mist/index.styl","hash":"ab16a3dcdc0393b9b582ef59dcc13db9320e917c","modified":1655723668635},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_sidebar.styl","hash":"d9141e6e14a56b5952488101e9a8388c2170e270","modified":1655723668603},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tables.styl","hash":"e840b23d33023e6d45e018f6e84b683dd56efd8d","modified":1655723668666},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_layout.styl","hash":"6eee86c8f0175d6c09e434053516cd8556f78d44","modified":1655723668511},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_menu.styl","hash":"72dc825c50357402c342d62ab60fc0c478ab6bc1","modified":1655723668513},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"778ed2ad5643b93970c95626b325defeb586733f","modified":1655723668604},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Pisces/index.styl","hash":"8000075b227749a7495eaf417cac6ccfbe441580","modified":1655723668636},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_header.styl","hash":"06080fd963c904d96c00eff098a284e337953013","modified":1655723668508},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_menu.styl","hash":"b7f48be3c43bfa393d62142544a5487a67871713","modified":1655723668512},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1655723668603},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_layout.styl","hash":"82a29572dd90451f75358a2ee2522b87304a0bb8","modified":1655723668510},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/_sidebar.styl","hash":"944364893bd7160d954c10ba931af641c91515a4","modified":1655723668599},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/gitter.js","hash":"cc38c94125f90dadde11b5ebac7d8bf99a1a08a2","modified":1655723667988},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1655723667963},{"_id":"node_modules/hexo-theme-next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1655723668636},{"_id":"node_modules/hexo-theme-next/source/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1655723668018},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1655723667955},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/changyan.js","hash":"260d1a77d6a3bb33a579d3e4cca1997003e799b5","modified":1655723667962},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqus.js","hash":"e1cc671b0d524864fd445e3ab4ade9ee6d07e565","modified":1655723667979},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1655723667990},{"_id":"node_modules/hexo-theme-next/source/js/third-party/analytics/google-analytics.js","hash":"59684383385059dc4f8a1ff85dbbeb703bcdbcb5","modified":1655723667989},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/disqusjs.js","hash":"b6c58f098473b526d6a3cd35655caf34b77f7cff","modified":1655723667981},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1655723667996},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1655723667987},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1655723667995},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1655723667999},{"_id":"node_modules/hexo-theme-next/source/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1655723668001},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/firestore.js","hash":"411a72df581f5b21317dc28633c7993207eb9e1c","modified":1655723667984},{"_id":"node_modules/hexo-theme-next/source/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1655723668094},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/algolia-search.js","hash":"fdb7b7cef1a147d897e7f7cd8903b58368ec2062","modified":1655723667953},{"_id":"node_modules/hexo-theme-next/source/js/third-party/search/local-search.js","hash":"4536cb6d0a9bbaaa86fab3fa0101f6a3a3ec5a76","modified":1655723668000},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/mermaid.js","hash":"f27d817b0c2138dd3215b1f46af0753f60a008f3","modified":1655723668003},{"_id":"node_modules/hexo-theme-next/source/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1655723668013},{"_id":"node_modules/hexo-theme-next/source/js/third-party/statistics/lean-analytics.js","hash":"5a928990856b8e456f0663cf3b6b406733672e39","modified":1655723667997},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/breadcrumb.styl","hash":"8afdc311c6b8db121758371f95cf1c5e77354f42","modified":1655723668613},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/index.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1655723668625},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/schedule.styl","hash":"6b816c2511242ee503fb5f34cd3e4dcdafc06b85","modified":1655723668658},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/categories.styl","hash":"b6e2eb1550a7845cb2adf86081a4ab6c7bde1e68","modified":1655723668614},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/pages/tag-cloud.styl","hash":"1a81d1a71fcf0699629ce6e72dfd0a15f3a2dd0a","modified":1655723668668},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/index.styl","hash":"d0805a763176b3c0003967401644f41dfe3bc9e8","modified":1655723668626},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-collapse.styl","hash":"ec37a36e94ba791663607a5022f763915778578f","modified":1655723668650},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-body.styl","hash":"d757768a58743601d0d84158ba955eb15d4c3c01","modified":1655723668648},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-followme.styl","hash":"fc1a7bac6493f24aa50665574f37f3dd954f210c","modified":1655723668651},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-header.styl","hash":"010c901e4ef49a606f8a350efbf09044e76d2ff3","modified":1655723668654},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-gallery.styl","hash":"aa366d37389760c8595529b850f461569577a1c5","modified":1655723668653},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-footer.styl","hash":"1d284f3ea03ba9b4feb76b375e539a8e0bccf1c3","modified":1655723668652},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-reward.styl","hash":"07cff69f2d57e6321595f64c16d8b763dc88df6a","modified":1655723668656},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-nav.styl","hash":"9ac6f477177264c26a46e8333b8456720a0444dc","modified":1655723668655},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/post/post-widgets.styl","hash":"b6677dc2a2368084ab82bb4f145ac79e5966c150","modified":1655723668656},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/gitalk.styl","hash":"070737d101e7cd58e997e8c7af09958268c43a21","modified":1655723668619},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/disqusjs.styl","hash":"c2326ee3e8b724d99c24a818ddee32813ea5bf89","modified":1655723668618},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/gitter.styl","hash":"35104dc6883a61c31e0e368dac8ac2f697be62fe","modified":1655723668621},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/index.styl","hash":"979486a41a81f2a9fd8b0b87c4f87d6416c68c7d","modified":1655723668626},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/search.styl","hash":"e72799ce3f9b79753e365b2f8c8ef6c310668d4a","modified":1655723668659},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/related-posts.styl","hash":"41ed817e1eb64078074e245e771446ee041e5790","modified":1655723668657},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/footer/index.styl","hash":"8b9407e5cfd0571ef8de7df19022b268f962fa2f","modified":1655723668628},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/math.styl","hash":"9d995eb4871a6c273d9d51558676a1fdabf69e72","modified":1655723668639},{"_id":"node_modules/hexo-theme-next/source/css/_common/components/third-party/utterances.styl","hash":"56d90ae0559caa55b75f3c300ff2711f9ed65fc4","modified":1655723668669},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/bookmark.styl","hash":"e74f4bb47a101b014ee2a1783c87f3b87323f9a0","modified":1655723668612},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/index.styl","hash":"ff642130354a0b3be0d708c43044ed4d710b5e83","modified":1655723668629},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/github-banner.styl","hash":"38c64c2d04e46848382bfa246a0e9c508294767b","modified":1655723668620},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/menu.styl","hash":"392fd53a8dd4e3f33a853ebb24290a622300e0ff","modified":1655723668640},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/site-meta.styl","hash":"759e582d34d08e3386c55d87a835a9523608619f","modified":1655723668664},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"52fc98b1435129eb3edb9293ced9e507741f1350","modified":1655723668659},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/index.styl","hash":"cee43480eba028c37d51cb620c2d81486aa24e01","modified":1655723668631},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/header/site-nav.styl","hash":"bf3ad8b4268f763a1e26377681644887694bc009","modified":1655723668665},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"5b38ac4a0f1ade0e681aff0e3366c481d9cf3dcd","modified":1655723668660},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"9950c3188a28e1c63b5498b7bdcd14b12ace3e28","modified":1655723668661},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"021a37cf178440cc341940a299d3bca359996c6b","modified":1655723668663},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"ee94a1a27090ad24e3ed579093088d97ff96d77d","modified":1655723668662},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"b926e368f702f8686aaa2eb98d3d2e533418958c","modified":1655723668661},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"fbdb63c6a8887d19b7137325ba7d6806f728139c","modified":1655723668662},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"3103b81fc76b59e1e2c161e2c484625c770ed66f","modified":1655723668664},{"_id":"node_modules/hexo-theme-next/source/css/_common/outline/sidebar/site-state.styl","hash":"26dd0adfcb1db6df29c6090c8d7e9b5a43583fb0","modified":1655723668665},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/index.styl","hash":"3f76c73a891bbc10679753e702feba9e8a5ffdd2","modified":1655723668633},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"d6418fd2bbfba7b73ddf11ec62db9637fdf5d8af","modified":1655723668610},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/highlight/index.styl","hash":"f2328caa94645836e06fb39a6a9c9a84ed68a8b5","modified":1655723668632},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"670fc109b56a010b166b86b616823a1aae97a738","modified":1655723668617},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"393ff96234e4196b569d4b11496774eb78e147de","modified":1655723668623},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/link-grid.styl","hash":"7f8a7345e6537a62cd9e9a94c8f7065b541d9b04","modified":1655723668638},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/label.styl","hash":"debee14539272fbe3835a7d3853af2230baa3501","modified":1655723668637},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/mermaid.styl","hash":"48d35dba575a7c9e8845b16652e76b7d4a4646de","modified":1655723668641},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b6654a1d7cf82577d8263faffee8af3ad4a5c0e8","modified":1655723668646},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/tabs.styl","hash":"7a39bcce7274284e87388743db62afc847fe6897","modified":1655723668667},{"_id":"node_modules/hexo-theme-next/source/css/_common/scaffolding/tags/note.styl","hash":"d27fbf7799695295dd5860a161a13ac4d90c5ba4","modified":1655723668645},{"_id":"node_modules/hexo-theme-next/source/images/taffy.png","hash":"0d16745194d0564ae77a71f5d3a381b64b5ec1fc","modified":1653934034116},{"_id":"node_modules/hexo-theme-next/source/images/2.jpg","hash":"3b37cdb16228cb83350d9efcf98ba06bfe34c589","modified":1653934034124},{"_id":"public/search.xml","hash":"ef51e4a780cd7c19ec230f8fe6db9565e1d5e4ad","modified":1655730640545},{"_id":"public/categories/index.html","hash":"fb1848adde02f326ff48d8872ad157c3163e182d","modified":1655730640545},{"_id":"public/tags/index.html","hash":"dee6669a27b45bb1d252dfcb6b3bd2643b71f6e1","modified":1655730640545},{"_id":"public/about/index.html","hash":"9a2162772588ddc0875035e6a245d92aac9f3190","modified":1655730640545},{"_id":"public/2022/05/24/About-Moby-Dick/index.html","hash":"9ed02ee0463005ff280ffc3405f79dff829ffbf0","modified":1655730640545},{"_id":"public/2022/05/23/testpic/index.html","hash":"cf923bd2feea0c12f79a1d41b6217e3510f5526f","modified":1655730640545},{"_id":"public/archives/index.html","hash":"f236b9fd52750a716088ea8a08f909c372eaea39","modified":1655730640545},{"_id":"public/archives/2022/index.html","hash":"381b95b60879073bd9551512fe4ea499940aa029","modified":1655730640545},{"_id":"public/archives/2022/05/index.html","hash":"00739dc73e93d1302065cb1e5f578acfa03d903e","modified":1655730640545},{"_id":"public/archives/2022/06/index.html","hash":"393b09d8b2e80fa1d0244e6cc829e6362c381ab6","modified":1655730640545},{"_id":"public/categories/Metaphysics/index.html","hash":"4862e6d03b75d6ccc6272dcc478b64bfff120bf6","modified":1655730640545},{"_id":"public/categories/Metaphysicsk/index.html","hash":"ed918ec8daeaf16cf9a4e2f3f5c3535ae097a211","modified":1655730640545},{"_id":"public/categories/Meow/index.html","hash":"d98389beed988d4c1d3c09e936d5ed37883e8553","modified":1655730640545},{"_id":"public/categories/Substance/index.html","hash":"10ddbc73b997e993cac8370a1413d1ce46eefa80","modified":1655730640545},{"_id":"public/tags/Moby-Dick/index.html","hash":"8c7a0bef8e062ea15803dbc105a872cfc69aae7d","modified":1655730640545},{"_id":"public/tags/Reading/index.html","hash":"6fdf8dde8824333708b9fa9eb7bb1f929b8427b4","modified":1655730640545},{"_id":"public/tags/Poem/index.html","hash":"82ceb0efa48b8e255ec4d934e97eb704731f3dc4","modified":1655730640545},{"_id":"public/tags/Literary-criticism/index.html","hash":"fa5fa2487748415e77b71d50074b3b8409e9d394","modified":1655730640545},{"_id":"public/tags/Philip-Larkin/index.html","hash":"323896bf365937b86f7b39e7dab4008c8bf26e4d","modified":1655730640545},{"_id":"public/tags/Ace/index.html","hash":"a754518c6b116328728c4ab7b4a1c920de4351a7","modified":1655730640545},{"_id":"public/tags/Taffy/index.html","hash":"8bed9b684d0bbe5947c74e2b54daefdfe7466191","modified":1655730640545},{"_id":"public/tags/ICSE-2022/index.html","hash":"e7e99f8129389b8bba7605ee0e405c2c608058a4","modified":1655730640545},{"_id":"public/tags/Code-generation/index.html","hash":"40f2b4bc008fc19f7c05b31b67538617d5ac7c31","modified":1655730640545},{"_id":"public/tags/Note/index.html","hash":"74f35c6db9d427793bff0c22fe81245515ecf64a","modified":1655730640545},{"_id":"public/tags/Self/index.html","hash":"88db9ceb55b405505bcd0ac4294027badf7f2992","modified":1655730640545},{"_id":"public/2022/06/05/Philip-Larkin/index.html","hash":"5a6e2702f1a5386559e3eacead733b52f0338276","modified":1655730640545},{"_id":"public/2022/05/29/火柴/index.html","hash":"6550a5eafa3da3e0a9eb321dff86b573d3f14144","modified":1655730640545},{"_id":"public/2022/05/27/SPT-Code/index.html","hash":"24fd2ae01f84f2bfb9dd386d1052c1ef57a9feaa","modified":1655730640545},{"_id":"public/index.html","hash":"69d788c3ac3b62592f8f293572a6f8e2d70bbbf4","modified":1655730640545},{"_id":"public/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1655730640545},{"_id":"public/images/logo.svg","hash":"2cb74fd3ea2635e015eabc58a8d488aed6cf6417","modified":1655730640545},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1655730640545},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1655730640545},{"_id":"public/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1655730640545},{"_id":"public/images/mine-32x32.png","hash":"13e8c0230b242bc68c3b54267ef0024d7fb11667","modified":1655730640545},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1655730640545},{"_id":"public/images/mine-16x16.png","hash":"46a56b8ee580a508fedfceff822c9dc8be0fa20d","modified":1655730640545},{"_id":"public/2022/05/23/testpic/image-20220523211852621.png","hash":"f443eb7116b28a70a135256d0d4521e3710e45ff","modified":1655730640545},{"_id":"public/2022/05/27/SPT-Code/image-20220527231806850.png","hash":"bdd3bb79709080c4bb8493ae66cd290e7b8b8237","modified":1655730640545},{"_id":"public/2022/05/27/SPT-Code/image-20220527233752649.png","hash":"add232d275639723c148095061934b6857daf254","modified":1655730640545},{"_id":"public/2022/05/27/SPT-Code/image-20220527233143119.png","hash":"d089096a54c50ed0ab12ae4dacbe4a85b2bcb6bc","modified":1655730640545},{"_id":"public/2022/05/27/SPT-Code/image-20220527230530594.png","hash":"ca5795fe19159888c5a97acb4f35f489db7ab7ed","modified":1655730640545},{"_id":"public/css/noscript.css","hash":"ec89b3425fbce20863d554c6fd495ea29c3c303d","modified":1655730640545},{"_id":"public/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1655730640545},{"_id":"public/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1655730640545},{"_id":"public/js/motion.js","hash":"f7c825cbff11885fa0dffa64824fd00e505d6a8d","modified":1655730640545},{"_id":"public/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1655730640545},{"_id":"public/js/pjax.js","hash":"919f5281c4a04d11cfd94573ecf57b3dbabd3cc8","modified":1655730640545},{"_id":"public/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1655730640545},{"_id":"public/js/next-boot.js","hash":"da0f07f9eaaa83de70128b0feaea3fdadb90457a","modified":1655730640545},{"_id":"public/js/utils.js","hash":"200088bfd042f5304b2a04befab0829148845e0e","modified":1655730640545},{"_id":"public/js/schemes/muse.js","hash":"9794bd4fc6a458322949d6a0ade89cd1026bc69f","modified":1655730640545},{"_id":"public/js/schedule.js","hash":"a1333258726caf84f368a8f8454639c7dc1626bb","modified":1655730640545},{"_id":"public/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1655730640545},{"_id":"public/js/third-party/rating.js","hash":"4e92c2d107ba47b47826829f9668030d5ea9bfb8","modified":1655730640545},{"_id":"public/js/third-party/fancybox.js","hash":"c098d14e65dd170537134358d4b8359ad0539c2c","modified":1655730640545},{"_id":"public/js/third-party/quicklink.js","hash":"eed02e6fced8e5a653077205d4d4d7834ca71472","modified":1655730640545},{"_id":"public/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1655730640545},{"_id":"public/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1655730640545},{"_id":"public/js/third-party/chat/gitter.js","hash":"cc38c94125f90dadde11b5ebac7d8bf99a1a08a2","modified":1655730640545},{"_id":"public/js/third-party/comments/changyan.js","hash":"260d1a77d6a3bb33a579d3e4cca1997003e799b5","modified":1655730640545},{"_id":"public/js/third-party/analytics/google-analytics.js","hash":"59684383385059dc4f8a1ff85dbbeb703bcdbcb5","modified":1655730640545},{"_id":"public/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1655730640545},{"_id":"public/js/third-party/comments/disqusjs.js","hash":"b6c58f098473b526d6a3cd35655caf34b77f7cff","modified":1655730640545},{"_id":"public/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1655730640545},{"_id":"public/js/third-party/comments/disqus.js","hash":"e1cc671b0d524864fd445e3ab4ade9ee6d07e565","modified":1655730640545},{"_id":"public/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1655730640545},{"_id":"public/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1655730640545},{"_id":"public/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1655730640545},{"_id":"public/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1655730640545},{"_id":"public/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1655730640545},{"_id":"public/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1655730640545},{"_id":"public/js/third-party/statistics/firestore.js","hash":"411a72df581f5b21317dc28633c7993207eb9e1c","modified":1655730640545},{"_id":"public/js/third-party/search/local-search.js","hash":"4536cb6d0a9bbaaa86fab3fa0101f6a3a3ec5a76","modified":1655730640545},{"_id":"public/js/third-party/search/algolia-search.js","hash":"fdb7b7cef1a147d897e7f7cd8903b58368ec2062","modified":1655730640545},{"_id":"public/js/third-party/tags/mermaid.js","hash":"f27d817b0c2138dd3215b1f46af0753f60a008f3","modified":1655730640545},{"_id":"public/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1655730640545},{"_id":"public/js/third-party/statistics/lean-analytics.js","hash":"5a928990856b8e456f0663cf3b6b406733672e39","modified":1655730640545},{"_id":"public/css/main.css","hash":"85d6f132baeed44c4d8ad6d0f0d140641aa5c4bb","modified":1655730640545},{"_id":"public/images/taffy.png","hash":"0d16745194d0564ae77a71f5d3a381b64b5ec1fc","modified":1655730640545},{"_id":"public/2022/05/27/SPT-Code/image-20220527232629535.png","hash":"22e81124540e148c61cb00bc3e3f986c71713087","modified":1655730640545},{"_id":"public/2022/05/23/testpic/image-20220524021029166.png","hash":"a4f4e62846dc739c9d970f5eea1b4414740f2184","modified":1655730640545},{"_id":"public/images/2.jpg","hash":"3b37cdb16228cb83350d9efcf98ba06bfe34c589","modified":1655730640545}],"Category":[{"name":"Metaphysics","_id":"cl4mr9vdm0004s0w9hdxl1tua"},{"name":"Metaphysicsk","_id":"cl4mr9vdr000as0w9er7i6i9c"},{"name":"Meow","_id":"cl4mr9vds000ds0w9b4faa3qo"},{"name":"Substance","_id":"cl4mr9vdt000js0w9efc6b6x2"}],"Data":[],"Page":[{"title":"Categories","date":"2022-05-23T17:41:53.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2022-05-24 01:41:53\ntype: categories\n---\n","updated":"2022-06-20T11:16:09.631Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cl4mr9vdd0000s0w9h0s11a06","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Tags","date":"2022-05-23T08:44:01.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2022-05-23 16:44:01\ntype: tags\n---\n","updated":"2022-06-20T11:16:09.632Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cl4mr9vdj0002s0w90ldhbnmi","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"About","date":"2022-05-23T17:42:53.000Z","type":"about","_content":"这里用来暂存英语写作积累\n\n```\nRecent years have seen the successful application of A to B, resulting in C\n\n````\n\n`aforementioned`\n上述的\n`henceforth`\n此后\n\n`In light of the above discussion`\n基于上述讨论\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2022-05-24 01:42:53\ntype: about\n---\n这里用来暂存英语写作积累\n\n```\nRecent years have seen the successful application of A to B, resulting in C\n\n````\n\n`aforementioned`\n上述的\n`henceforth`\n此后\n\n`In light of the above discussion`\n基于上述讨论\n","updated":"2022-06-20T11:16:09.631Z","path":"about/index.html","comments":1,"layout":"page","_id":"cl4mr9vdn0006s0w973f0gjpd","content":"<p>这里用来暂存英语写作积累</p>\n<pre><code>Recent years have seen the successful application of A to B, resulting in C\n</code></pre>\n<p><code>aforementioned</code><br>上述的<br><code>henceforth</code><br>此后</p>\n<p><code>In light of the above discussion</code><br>基于上述讨论</p>\n","site":{"data":{}},"excerpt":"","more":"<p>这里用来暂存英语写作积累</p>\n<pre><code>Recent years have seen the successful application of A to B, resulting in C\n</code></pre>\n<p><code>aforementioned</code><br>上述的<br><code>henceforth</code><br>此后</p>\n<p><code>In light of the above discussion</code><br>基于上述讨论</p>\n"}],"Post":[{"title":"About Moby Dick","date":"2022-05-23T19:07:49.000Z","_content":"> 现在，除了一艘轻轻摇晃的船赋予你的摇摆不定的生命，你没有生命；船的生命借自于大海；大海的生命借自于上帝神秘难测的潮汐。可是，当这睡眠，这幻梦将你笼罩，你的手或脚要是稍微挪动一下——你的双手彻底松开——你就会在惊恐中能够恢复自己的本性。你就盘旋在笛卡尔的涡流之上了。而也许，恰当正午，又是响晴的天气，你便随着一声半带窒息的尖叫，穿过透明的空气，坠入夏天的海洋，再也没有浮上来。好好留神吧，你们这些泛神论者！——《白鲸》桅顶瞭望\n\n\n> There is no life in thee, now, expect that rocking life imparted by a gently rolling ship; by her, borrowed from the sea; by the sea, from the inscrutable tides of God. But while this sleep, this dream is on ye, move your foot or hand an inch, slip your hold at all; and your identity comes back in horror. Over Descartian vortices you hover. And perhaps, at mid-day, in the fairest weather, with one half-throttled shriek you drop through that transparent air into the summer sea, no more to rise for ever. Heed it well, ye Pantheists! ——&lt;Moby dick> CHAPTER 35 The Mast-Head\n","source":"_posts/About-Moby-Dick.md","raw":"---\ntitle: About Moby Dick\ndate: 2022-05-24 03:07:49\ntags: \n- Moby Dick\n- Reading\ncategories:\n- Metaphysics\n---\n> 现在，除了一艘轻轻摇晃的船赋予你的摇摆不定的生命，你没有生命；船的生命借自于大海；大海的生命借自于上帝神秘难测的潮汐。可是，当这睡眠，这幻梦将你笼罩，你的手或脚要是稍微挪动一下——你的双手彻底松开——你就会在惊恐中能够恢复自己的本性。你就盘旋在笛卡尔的涡流之上了。而也许，恰当正午，又是响晴的天气，你便随着一声半带窒息的尖叫，穿过透明的空气，坠入夏天的海洋，再也没有浮上来。好好留神吧，你们这些泛神论者！——《白鲸》桅顶瞭望\n\n\n> There is no life in thee, now, expect that rocking life imparted by a gently rolling ship; by her, borrowed from the sea; by the sea, from the inscrutable tides of God. But while this sleep, this dream is on ye, move your foot or hand an inch, slip your hold at all; and your identity comes back in horror. Over Descartian vortices you hover. And perhaps, at mid-day, in the fairest weather, with one half-throttled shriek you drop through that transparent air into the summer sea, no more to rise for ever. Heed it well, ye Pantheists! ——&lt;Moby dick> CHAPTER 35 The Mast-Head\n","slug":"About-Moby-Dick","published":1,"updated":"2022-06-20T11:16:09.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4mr9vdg0001s0w996o99a6j","content":"<blockquote>\n<p>现在，除了一艘轻轻摇晃的船赋予你的摇摆不定的生命，你没有生命；船的生命借自于大海；大海的生命借自于上帝神秘难测的潮汐。可是，当这睡眠，这幻梦将你笼罩，你的手或脚要是稍微挪动一下——你的双手彻底松开——你就会在惊恐中能够恢复自己的本性。你就盘旋在笛卡尔的涡流之上了。而也许，恰当正午，又是响晴的天气，你便随着一声半带窒息的尖叫，穿过透明的空气，坠入夏天的海洋，再也没有浮上来。好好留神吧，你们这些泛神论者！——《白鲸》桅顶瞭望</p>\n</blockquote>\n<blockquote>\n<p>There is no life in thee, now, expect that rocking life imparted by a gently rolling ship; by her, borrowed from the sea; by the sea, from the inscrutable tides of God. But while this sleep, this dream is on ye, move your foot or hand an inch, slip your hold at all; and your identity comes back in horror. Over Descartian vortices you hover. And perhaps, at mid-day, in the fairest weather, with one half-throttled shriek you drop through that transparent air into the summer sea, no more to rise for ever. Heed it well, ye Pantheists! ——&lt;Moby dick&gt; CHAPTER 35 The Mast-Head</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>现在，除了一艘轻轻摇晃的船赋予你的摇摆不定的生命，你没有生命；船的生命借自于大海；大海的生命借自于上帝神秘难测的潮汐。可是，当这睡眠，这幻梦将你笼罩，你的手或脚要是稍微挪动一下——你的双手彻底松开——你就会在惊恐中能够恢复自己的本性。你就盘旋在笛卡尔的涡流之上了。而也许，恰当正午，又是响晴的天气，你便随着一声半带窒息的尖叫，穿过透明的空气，坠入夏天的海洋，再也没有浮上来。好好留神吧，你们这些泛神论者！——《白鲸》桅顶瞭望</p>\n</blockquote>\n<blockquote>\n<p>There is no life in thee, now, expect that rocking life imparted by a gently rolling ship; by her, borrowed from the sea; by the sea, from the inscrutable tides of God. But while this sleep, this dream is on ye, move your foot or hand an inch, slip your hold at all; and your identity comes back in horror. Over Descartian vortices you hover. And perhaps, at mid-day, in the fairest weather, with one half-throttled shriek you drop through that transparent air into the summer sea, no more to rise for ever. Heed it well, ye Pantheists! ——&lt;Moby dick&gt; CHAPTER 35 The Mast-Head</p>\n</blockquote>\n"},{"title":"Philip Larkin 诗鉴赏","date":"2022-06-04T17:26:03.000Z","_content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n今天读到了Philip Larkin(菲利普·拉金) 觉得他确实写出了一些人类的共有困境，是超越东西方的 也不好说是现代视角或者古典视角。用诗歌描述一种……symptom？没有意象的堆叠或者是故作惊人之语。恰到好处的建筑与音韵意识又不喧宾夺主，克制的情感流露并着个人色彩。 类似于散文诗？\n\n现摘在这里这一首，「Love Songs in Age」\n\n> She kept her songs, they kept so little space,\n> The covers pleased her:\n> One bleached[^1] from lying in a sunny place,\n> One marked in circles by a vase of water,\n> One mended[^2], when a tidy fit had seized her,\n> And coloured, by her daughter -\n> So they had waited, till, in widowhood\n> She found them, looking for something else, and stood\n>\n> Relearning how each frank submissive chord[^3]\n> Had ushered[^4] in\n> Word after sprawling hyphenated[^5] word,\n> And the unfailing sense of being young\n> Spread out like a spring-woken tree, wherein\n> That hidden freshness sung,\n> That certainty of time laid up in store\n> As when she played them first. But, even more,\n>\n> The glare[^6] of that much-mentionned brilliance, love,\n> Broke out, to show\n> Its bright incipience[^7] sailing above,\n> Still promising to solve, and satisfy,\n> And set unchangeably in order. So\n> To pile them back, to cry,\n> Was hard, without lamely[^8] admitting how\n> It had not done so then, and could not now.\n\n[^1]: floating, drift,漂白\n[^2]: repair,patch,修补\n[^3]:和弦\n[^4]:（迎宾员式的）引导\n[^5]:连字符\n[^6 ]:great brightness,耀眼的\n[^7]:beginning to exist or to be apparent\n[^8]:in a weak and unconvincing manner\n\n","source":"_posts/Philip-Larkin.md","raw":"---\ntitle: Philip Larkin 诗鉴赏\ndate: 2022-06-05 01:26:03\ntags:\n- Poem\n- Literary criticism\n- Philip Larkin\n\ncategories:\n- Metaphysicsk\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n今天读到了Philip Larkin(菲利普·拉金) 觉得他确实写出了一些人类的共有困境，是超越东西方的 也不好说是现代视角或者古典视角。用诗歌描述一种……symptom？没有意象的堆叠或者是故作惊人之语。恰到好处的建筑与音韵意识又不喧宾夺主，克制的情感流露并着个人色彩。 类似于散文诗？\n\n现摘在这里这一首，「Love Songs in Age」\n\n> She kept her songs, they kept so little space,\n> The covers pleased her:\n> One bleached[^1] from lying in a sunny place,\n> One marked in circles by a vase of water,\n> One mended[^2], when a tidy fit had seized her,\n> And coloured, by her daughter -\n> So they had waited, till, in widowhood\n> She found them, looking for something else, and stood\n>\n> Relearning how each frank submissive chord[^3]\n> Had ushered[^4] in\n> Word after sprawling hyphenated[^5] word,\n> And the unfailing sense of being young\n> Spread out like a spring-woken tree, wherein\n> That hidden freshness sung,\n> That certainty of time laid up in store\n> As when she played them first. But, even more,\n>\n> The glare[^6] of that much-mentionned brilliance, love,\n> Broke out, to show\n> Its bright incipience[^7] sailing above,\n> Still promising to solve, and satisfy,\n> And set unchangeably in order. So\n> To pile them back, to cry,\n> Was hard, without lamely[^8] admitting how\n> It had not done so then, and could not now.\n\n[^1]: floating, drift,漂白\n[^2]: repair,patch,修补\n[^3]:和弦\n[^4]:（迎宾员式的）引导\n[^5]:连字符\n[^6 ]:great brightness,耀眼的\n[^7]:beginning to exist or to be apparent\n[^8]:in a weak and unconvincing manner\n\n","slug":"Philip-Larkin","published":1,"updated":"2022-06-20T11:41:55.092Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4mr9vdk0003s0w92i011c6f","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><p>今天读到了Philip Larkin(菲利普·拉金) 觉得他确实写出了一些人类的共有困境，是超越东西方的 也不好说是现代视角或者古典视角。用诗歌描述一种……symptom？没有意象的堆叠或者是故作惊人之语。恰到好处的建筑与音韵意识又不喧宾夺主，克制的情感流露并着个人色彩。 类似于散文诗？</p>\n<p>现摘在这里这一首，「Love Songs in Age」</p>\n<blockquote>\n<p>She kept her songs, they kept so little space,<br>The covers pleased her:<br>One bleached<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"floating, drift,漂白\n\">1</span></a></sup> from lying in a sunny place,<br>One marked in circles by a vase of water,<br>One mended<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"repair,patch,修补\n\">2</span></a></sup>, when a tidy fit had seized her,<br>And coloured, by her daughter -<br>So they had waited, till, in widowhood<br>She found them, looking for something else, and stood</p>\n<p>Relearning how each frank submissive chord<sup id=\"fnref:3\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"和弦\n\">3</span></a></sup><br>Had ushered<sup id=\"fnref:4\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"（迎宾员式的）引导\n\">4</span></a></sup> in<br>Word after sprawling hyphenated<sup id=\"fnref:5\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"连字符\n[^6 ]:great brightness,耀眼的\n\">5</span></a></sup> word,<br>And the unfailing sense of being young<br>Spread out like a spring-woken tree, wherein<br>That hidden freshness sung,<br>That certainty of time laid up in store<br>As when she played them first. But, even more,</p>\n<p>The glare<sup id=\"fnref:6\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label>6</span></a></sup> of that much-mentionned brilliance, love,<br>Broke out, to show<br>Its bright incipience<sup id=\"fnref:7\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"beginning to exist or to be apparent\n\">7</span></a></sup> sailing above,<br>Still promising to solve, and satisfy,<br>And set unchangeably in order. So<br>To pile them back, to cry,<br>Was hard, without lamely<sup id=\"fnref:8\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"in a weak and unconvincing manner\">8</span></a></sup> admitting how<br>It had not done so then, and could not now.</p>\n</blockquote>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">floating, drift,漂白<a href=\"#fnref:1\" rev=\"footnote\">↩</a></span></li><li id=\"fn:2\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">2.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">repair,patch,修补<a href=\"#fnref:2\" rev=\"footnote\">↩</a></span></li><li id=\"fn:3\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">3.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">和弦<a href=\"#fnref:3\" rev=\"footnote\">↩</a></span></li><li id=\"fn:4\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">4.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">（迎宾员式的）引导<a href=\"#fnref:4\" rev=\"footnote\">↩</a></span></li><li id=\"fn:5\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">5.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">连字符\n[^6 ]:great brightness,耀眼的<a href=\"#fnref:5\" rev=\"footnote\">↩</a></span></li><li id=\"fn:7\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">7.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">beginning to exist or to be apparent<a href=\"#fnref:7\" rev=\"footnote\">↩</a></span></li><li id=\"fn:8\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">8.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">in a weak and unconvincing manner<a href=\"#fnref:8\" rev=\"footnote\">↩</a></span></li></ol></div></div>","site":{"data":{}},"excerpt":"","more":"<p>今天读到了Philip Larkin(菲利普·拉金) 觉得他确实写出了一些人类的共有困境，是超越东西方的 也不好说是现代视角或者古典视角。用诗歌描述一种……symptom？没有意象的堆叠或者是故作惊人之语。恰到好处的建筑与音韵意识又不喧宾夺主，克制的情感流露并着个人色彩。 类似于散文诗？</p>\n<p>现摘在这里这一首，「Love Songs in Age」</p>\n<blockquote>\n<p>She kept her songs, they kept so little space,<br>The covers pleased her:<br>One bleached<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"floating, drift,漂白\n\">1</span></a></sup> from lying in a sunny place,<br>One marked in circles by a vase of water,<br>One mended<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"repair,patch,修补\n\">2</span></a></sup>, when a tidy fit had seized her,<br>And coloured, by her daughter -<br>So they had waited, till, in widowhood<br>She found them, looking for something else, and stood</p>\n<p>Relearning how each frank submissive chord<sup id=\"fnref:3\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"和弦\n\">3</span></a></sup><br>Had ushered<sup id=\"fnref:4\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"（迎宾员式的）引导\n\">4</span></a></sup> in<br>Word after sprawling hyphenated<sup id=\"fnref:5\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"连字符\n[^6 ]:great brightness,耀眼的\n\">5</span></a></sup> word,<br>And the unfailing sense of being young<br>Spread out like a spring-woken tree, wherein<br>That hidden freshness sung,<br>That certainty of time laid up in store<br>As when she played them first. But, even more,</p>\n<p>The glare<sup id=\"fnref:6\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label>6</span></a></sup> of that much-mentionned brilliance, love,<br>Broke out, to show<br>Its bright incipience<sup id=\"fnref:7\"><a href=\"#fn:7\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"beginning to exist or to be apparent\n\">7</span></a></sup> sailing above,<br>Still promising to solve, and satisfy,<br>And set unchangeably in order. So<br>To pile them back, to cry,<br>Was hard, without lamely<sup id=\"fnref:8\"><a href=\"#fn:8\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"in a weak and unconvincing manner\">8</span></a></sup> admitting how<br>It had not done so then, and could not now.</p>\n</blockquote>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">floating, drift,漂白<a href=\"#fnref:1\" rev=\"footnote\">↩</a></span></li><li id=\"fn:2\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">2.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">repair,patch,修补<a href=\"#fnref:2\" rev=\"footnote\">↩</a></span></li><li id=\"fn:3\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">3.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">和弦<a href=\"#fnref:3\" rev=\"footnote\">↩</a></span></li><li id=\"fn:4\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">4.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">（迎宾员式的）引导<a href=\"#fnref:4\" rev=\"footnote\">↩</a></span></li><li id=\"fn:5\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">5.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">连字符\n[^6 ]:great brightness,耀眼的<a href=\"#fnref:5\" rev=\"footnote\">↩</a></span></li><li id=\"fn:7\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">7.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">beginning to exist or to be apparent<a href=\"#fnref:7\" rev=\"footnote\">↩</a></span></li><li id=\"fn:8\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">8.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">in a weak and unconvincing manner<a href=\"#fnref:8\" rev=\"footnote\">↩</a></span></li></ol></div></div>"},{"title":"Follow Ace Taffy Meow！","date":"2022-05-23T12:33:42.000Z","_content":"```python\nprint('Follow Ace Taffy thanks Meow!')\n```\n![image-20220524021029166](testpic/image-20220524021029166.png)\n","source":"_posts/testpic.md","raw":"---\ntitle: Follow Ace Taffy Meow！\ndate: 2022-05-23 20:33:42\ncategories: \n- Meow\ntags:\n- Ace\n- Taffy\n---\n```python\nprint('Follow Ace Taffy thanks Meow!')\n```\n![image-20220524021029166](testpic/image-20220524021029166.png)\n","slug":"testpic","published":1,"updated":"2022-06-20T11:16:09.626Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4mr9vdo0007s0w9g4fd91zy","content":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Follow Ace Taffy thanks Meow!&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2022/05/23/testpic/image-20220524021029166.png\" alt=\"image-20220524021029166\"></p>\n","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Follow Ace Taffy thanks Meow!&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2022/05/23/testpic/image-20220524021029166.png\" alt=\"image-20220524021029166\"></p>\n"},{"title":"SPT-Code","date":"2022-05-27T07:58:33.000Z","_content":"\n\n\n\n\n\n\n这是《Sequence-to-Sequence Pre-Training for Learning Source Code Representations》的读书笔记\n\n<!--more-->\n\n\n\n# Abstract\n\nPre-trained models 用于代码相关下游任务的应用时的 问题？\n\n\n\n1. 仅用了Pre-trained encoder 但生成任务需要两个部件都预训练\n2. 现在许多Pre-trained model 包括T5，只是简单复用了NL的预训练任务，这要求NL-CODE的corpus 这使得数据受限\n\n为了应对这两个问题 提出了SPT-Code ，在微调后可以在5个代码相关任务上SOTA\n\n这是一个seq2seq 预训练模型，通过三个预训练任务使得其能够学习到下面三点，并在下游任务中使用\n\n* 代码知识\n* 对应代码结构\n* 自然语言描述\n\n而不需要双语corpus\n\n# Introduction\n\n作者在第一部分提了自监督训练，然后说预训练模型的成功和这个有关系，下面谈预训练模型到软工SE任务的时候认为的问题是：\n\n* 主流预训练模型仅对encoder搞 ，不够理想\n\n  最有名的encoder也就是BERT吧 也确实就是用了MLM（Masked Language Modeling） 也确实有好多Pre-trained Bert 下面套个任务头或者另一个decoder就开干的……不过这应该算是蛮荒时代了 T5虽然好 但是对一般研究人员来说想改进模型architecture 不是那么容易？\n\n  * 别人的解决：\n\n    T5-learning , TreeBERT 两个工作使得Encoder-Decoder jointly trainded\n\n    \n\n* 这些预训练模型预设输入的是NL-CODE 忽视了代码结构\n\n  为什么呢？因为就是简单偷了NLP的拿来用\n\n  * 别人的解决：\n\n    专门的预训练任务 包括预测数据流图中的边与对齐节点和代码 \n\n    ——dataflow 有语义信息而无语法信息（AST）\n\n* 而且都假设有严格对齐的双语语料\n\n  * T5-learning :\n\n    分别处理两种输入，不要求语料库中展示二者的关系\n\n\n\n—— 没有一个模型能够统一处理这三个问题\n\nSPT-Code就可以！\n\n* 这是一个encoder-decoder共同预训练的模型\n* 数据实例由CODE,AST,NL三部分构成\n* 使用方法名和调用此方法的方式作为自然语言描述（以避免对bilingual corpus的依赖）\n\n\n\n方法：\n\n设计了三种预训练任务，每一种获取一种数据信息\n\n* 改进的MASS-用于CODE：遮蔽Seq2Seq恢复\n* Code-AST Predict CAP：预测code-AST是否匹配\n* Method Name Generation MNG：生成 方法名的 子token\n\n数据集：\n\nCodeSearchNet\n\n贡献：\n\n1. 提出了SPT-Code预训练模型，可用于分类和生成任务\n2. 使用了线性和简化的AST 第一个使用了NL&AST作为输入对于预训练\n3. 通过输入表示和三个与训练任务使得预训练模型不依赖双语语料库（labeled data)\n4. 用未标注数据库在五个下游任务实现了SOTA\n\n# 方法\n\n架构，输入和预训练任务，微调\n\n\n\n## 架构\n\n类似于BART和T5的典型Transformer\n\n分类任务和生成任务，模型采用相同的输入：\n\n* 分类对encoder和decoder输入相同\n* 生成采用传统方法\n\n<img src=\"SPT-Code/image-20220527230530594.png\" alt=\"image-20220527230530594\" style=\"zoom:50%;\" />\n\n## 输入\n\n<img src=\"SPT-Code/image-20220527231806850.png\" alt=\"image-20220527231806850\" style=\"zoom:50%;\" />\n\n由三部分组成，每一部分[SEP]连接\n\n### Code：\n\n没有使用笨蛋tokenizer，而是用了stl for Python 或者 antlr for Java,Php.etc 其他的用了NLTK\n\n###  AST\n\n用的Tree-sitter 搞的 AST \n\n 如何序列化AST?\n\n* 传统方法：SBT （Structure-Based Traversal)\n\n  比先序遍历之类的更有效，但可能产生过长的序列（可能超过代码三倍长）\n\n  <img src=\"SPT-Code/image-20220527232629535.png\" alt=\"image-20220527232629535\" style=\"zoom:50%;\" />\n\n  <center>\n      一种类似中序遍历的说法 来自那篇论文忘了 反正绝对看过\n  </center>\n  \n  \n* 本文的方法：X-SBT：XML-like SBT\n\n  可以减少超过一半的长度\n\n  <img src=\"SPT-Code/image-20220527233143119.png\" alt=\"image-20220527233143119\" style=\"zoom:67%;\" />\n\n  论文自带的图好看一点 这个创新点……只能说是情理之中，毕竟原来那个也太呆了（作者甚至还装模做样证了一下必然更短）\n\n  为了更短: AST——XSBT时，仅取表达式级别以上节点，放弃终结符\n\n  <img src=\"SPT-Code/image-20220527233752649.png\" alt=\"image-20220527233752649\" style=\"zoom:50%;\" />\n\n  **这种优化为可接受的，为什么呢？下面这个说得很漂亮：**\n\n  AST中包含了语法信息和词法信息，舍弃掉终结符丢失了词法信息，但之前的token（Input中Code的部分）都是词法单元，所以这个信息是没有丢掉的，因此改进可接受\n\n### NL\n\n难点：从仅有CODE中提取NL\n\n方法：获取方法名与调用的API序列\n\n对驼峰和下划线命名掰开\n\n问题：怎么提取的API序列：从AST里偷出来的？\n\n——应该就是\n\n## 预训练任务\n\n\n\n𝐼𝑛𝑝𝑢𝑡 = 𝐶,[SEP],𝐴,[SEP],𝑁 \n\n### Code-AST Prediction.\n\n这是第一个\n\n在构建输入𝐼𝑛𝑝𝑢𝑡 时，一半是对应的AST,一半是随机的AST\n\n### MASS\n\n随机遮蔽C中的一部分，将所有遮蔽的token设置为[MASK]（改进前为对应数量个[MASK])\n\n根据别人的论文，最大遮蔽长度是C长度l的一半\n\n\n\n### Method Name Generation\n\n希望可以通过这个任务学到代码的动机\n\n代码名的词汇和对应代码总结的词汇由高度相关，因此希望通过改善 预测代码名 这一任务提升 代码总结 的能力\n\n此任务的输入时，从𝐼𝑛𝑝𝑢𝑡中的C扣掉对应token，并在N中去掉前s个token（方法名总在最前），作为输入，试图让decoder输出扣掉的前s个token，即方法名\n\n\n\n\n\n## 微调\n\n端到端 根据不同任务分成两类，分类或生成，不同任务就缺掉一点输入\n\n# 实验\n\n## 预训练\n\n交代了数据集的数据使用，任务顺序，epoches，用的cross-entropy loss和Adam-W，batchsize和显卡（……）\n\nTokenizer Encoding 用的BPE对CODE和NL，在预训练data上干过 每个下游任务照用\n\n预训练任务的任务量都是每个任务几十个Epoches的量级。\n\n\n\n问题：不是都有token了 还tokenize？\n\n——低级问题，前面的应该是tokenize，这里进行token=>input_ids的步骤\n\n## 下游任务微调\n\n介绍了五个任务 其中介绍部分有点尴尬\n\n\n\n## 评估\n\nRQ1:相比于其他较好的基线 这个性能在下游任务如何？\n\n列个表 比不上人家的扯一点\n\n\n\nRQ2:三个预训练任务对五个下游任务分别有什么贡献？\n\n——消融实验\n\n有趣的是 删除掉MNG （生成 方法的token）在代码完成和代码修复上性能有所提高：\n\n* MNG是目标自然语言的预训练，而这两项任务都是代码到代码\n\n分析一下 什么任务对什么下游有影响\n\n\n\n**稍微有点水平的问题**\n\nRQ3: 可以利用更多无标记的资料是不是本模型的优点呢？\n\n相较于别的预训练模型，由于它的设计，可以使用无标注数据。更好的性能是不是来自于更多的数据呢？（而不是模型本身厉害？）\n\n在同样的数据集上训练——把它当作无标注的——其实和别的比还算吃亏——也能够取得相对别的模型更好的结果。\n\n可以说是赢两遍了。\n\n\n\nRQ4:微调阶段的数据量对下游任务有什么影响？\n\n虽然越小越坏，但是很小也和别的模型差不多 说明真好\n\n\n\n\n\n## 定性分析与定量分析\n\n定量：志愿者评估，多个样本分类列表个\n\n定性：在哪些任务哪些方面表现好 不好的怎么不好\n\n\n\n# 威胁分析\n\n构造：数据集可能有重复\n\n内部：没调过超参数：所以可能有更好的\n\n外部：只用了CodesearchNet\n\n\n\n# 总结：\n\n我们介绍了SPT-Code，这是一个基于编码器架构的源代码的大型型号。首先，我们为预训练SPT代码设计了三个特定代码的预训练任务。其次，我们提出了一种新的输入表示形式，它是第一个考虑自然语言和AST形式的方法，我们还提出了AST遍历方法的改进版本XSBT。我们的预训练任务和输入表示形式都允许在完全未标记的数据集上预先训练SPT代码。然后，对五个与代码相关的下游任务进行了微调。结果表明，微调SPT代码使其能够在五个与代码相关的下游任务上实现最新性能。消融实验表明，这三个预训练任务对不同的下游任务具有不同程度的影响，AST和自然语言输入也有助于提高SPTCODE的性能。为了促进未来的研究，我们还可以在https://github.com/ nougatca/spt-code上公开提供代码和其他。\n\n\n\n\n\n","source":"_posts/SPT-Code.md","raw":"---\ntitle: SPT-Code \ndate: 2022-05-27 15:58:33\ntags:\n- ICSE 2022\n- Code generation\n- Note\ncategories:\n- Substance\n---\n\n\n\n\n\n\n\n这是《Sequence-to-Sequence Pre-Training for Learning Source Code Representations》的读书笔记\n\n<!--more-->\n\n\n\n# Abstract\n\nPre-trained models 用于代码相关下游任务的应用时的 问题？\n\n\n\n1. 仅用了Pre-trained encoder 但生成任务需要两个部件都预训练\n2. 现在许多Pre-trained model 包括T5，只是简单复用了NL的预训练任务，这要求NL-CODE的corpus 这使得数据受限\n\n为了应对这两个问题 提出了SPT-Code ，在微调后可以在5个代码相关任务上SOTA\n\n这是一个seq2seq 预训练模型，通过三个预训练任务使得其能够学习到下面三点，并在下游任务中使用\n\n* 代码知识\n* 对应代码结构\n* 自然语言描述\n\n而不需要双语corpus\n\n# Introduction\n\n作者在第一部分提了自监督训练，然后说预训练模型的成功和这个有关系，下面谈预训练模型到软工SE任务的时候认为的问题是：\n\n* 主流预训练模型仅对encoder搞 ，不够理想\n\n  最有名的encoder也就是BERT吧 也确实就是用了MLM（Masked Language Modeling） 也确实有好多Pre-trained Bert 下面套个任务头或者另一个decoder就开干的……不过这应该算是蛮荒时代了 T5虽然好 但是对一般研究人员来说想改进模型architecture 不是那么容易？\n\n  * 别人的解决：\n\n    T5-learning , TreeBERT 两个工作使得Encoder-Decoder jointly trainded\n\n    \n\n* 这些预训练模型预设输入的是NL-CODE 忽视了代码结构\n\n  为什么呢？因为就是简单偷了NLP的拿来用\n\n  * 别人的解决：\n\n    专门的预训练任务 包括预测数据流图中的边与对齐节点和代码 \n\n    ——dataflow 有语义信息而无语法信息（AST）\n\n* 而且都假设有严格对齐的双语语料\n\n  * T5-learning :\n\n    分别处理两种输入，不要求语料库中展示二者的关系\n\n\n\n—— 没有一个模型能够统一处理这三个问题\n\nSPT-Code就可以！\n\n* 这是一个encoder-decoder共同预训练的模型\n* 数据实例由CODE,AST,NL三部分构成\n* 使用方法名和调用此方法的方式作为自然语言描述（以避免对bilingual corpus的依赖）\n\n\n\n方法：\n\n设计了三种预训练任务，每一种获取一种数据信息\n\n* 改进的MASS-用于CODE：遮蔽Seq2Seq恢复\n* Code-AST Predict CAP：预测code-AST是否匹配\n* Method Name Generation MNG：生成 方法名的 子token\n\n数据集：\n\nCodeSearchNet\n\n贡献：\n\n1. 提出了SPT-Code预训练模型，可用于分类和生成任务\n2. 使用了线性和简化的AST 第一个使用了NL&AST作为输入对于预训练\n3. 通过输入表示和三个与训练任务使得预训练模型不依赖双语语料库（labeled data)\n4. 用未标注数据库在五个下游任务实现了SOTA\n\n# 方法\n\n架构，输入和预训练任务，微调\n\n\n\n## 架构\n\n类似于BART和T5的典型Transformer\n\n分类任务和生成任务，模型采用相同的输入：\n\n* 分类对encoder和decoder输入相同\n* 生成采用传统方法\n\n<img src=\"SPT-Code/image-20220527230530594.png\" alt=\"image-20220527230530594\" style=\"zoom:50%;\" />\n\n## 输入\n\n<img src=\"SPT-Code/image-20220527231806850.png\" alt=\"image-20220527231806850\" style=\"zoom:50%;\" />\n\n由三部分组成，每一部分[SEP]连接\n\n### Code：\n\n没有使用笨蛋tokenizer，而是用了stl for Python 或者 antlr for Java,Php.etc 其他的用了NLTK\n\n###  AST\n\n用的Tree-sitter 搞的 AST \n\n 如何序列化AST?\n\n* 传统方法：SBT （Structure-Based Traversal)\n\n  比先序遍历之类的更有效，但可能产生过长的序列（可能超过代码三倍长）\n\n  <img src=\"SPT-Code/image-20220527232629535.png\" alt=\"image-20220527232629535\" style=\"zoom:50%;\" />\n\n  <center>\n      一种类似中序遍历的说法 来自那篇论文忘了 反正绝对看过\n  </center>\n  \n  \n* 本文的方法：X-SBT：XML-like SBT\n\n  可以减少超过一半的长度\n\n  <img src=\"SPT-Code/image-20220527233143119.png\" alt=\"image-20220527233143119\" style=\"zoom:67%;\" />\n\n  论文自带的图好看一点 这个创新点……只能说是情理之中，毕竟原来那个也太呆了（作者甚至还装模做样证了一下必然更短）\n\n  为了更短: AST——XSBT时，仅取表达式级别以上节点，放弃终结符\n\n  <img src=\"SPT-Code/image-20220527233752649.png\" alt=\"image-20220527233752649\" style=\"zoom:50%;\" />\n\n  **这种优化为可接受的，为什么呢？下面这个说得很漂亮：**\n\n  AST中包含了语法信息和词法信息，舍弃掉终结符丢失了词法信息，但之前的token（Input中Code的部分）都是词法单元，所以这个信息是没有丢掉的，因此改进可接受\n\n### NL\n\n难点：从仅有CODE中提取NL\n\n方法：获取方法名与调用的API序列\n\n对驼峰和下划线命名掰开\n\n问题：怎么提取的API序列：从AST里偷出来的？\n\n——应该就是\n\n## 预训练任务\n\n\n\n𝐼𝑛𝑝𝑢𝑡 = 𝐶,[SEP],𝐴,[SEP],𝑁 \n\n### Code-AST Prediction.\n\n这是第一个\n\n在构建输入𝐼𝑛𝑝𝑢𝑡 时，一半是对应的AST,一半是随机的AST\n\n### MASS\n\n随机遮蔽C中的一部分，将所有遮蔽的token设置为[MASK]（改进前为对应数量个[MASK])\n\n根据别人的论文，最大遮蔽长度是C长度l的一半\n\n\n\n### Method Name Generation\n\n希望可以通过这个任务学到代码的动机\n\n代码名的词汇和对应代码总结的词汇由高度相关，因此希望通过改善 预测代码名 这一任务提升 代码总结 的能力\n\n此任务的输入时，从𝐼𝑛𝑝𝑢𝑡中的C扣掉对应token，并在N中去掉前s个token（方法名总在最前），作为输入，试图让decoder输出扣掉的前s个token，即方法名\n\n\n\n\n\n## 微调\n\n端到端 根据不同任务分成两类，分类或生成，不同任务就缺掉一点输入\n\n# 实验\n\n## 预训练\n\n交代了数据集的数据使用，任务顺序，epoches，用的cross-entropy loss和Adam-W，batchsize和显卡（……）\n\nTokenizer Encoding 用的BPE对CODE和NL，在预训练data上干过 每个下游任务照用\n\n预训练任务的任务量都是每个任务几十个Epoches的量级。\n\n\n\n问题：不是都有token了 还tokenize？\n\n——低级问题，前面的应该是tokenize，这里进行token=>input_ids的步骤\n\n## 下游任务微调\n\n介绍了五个任务 其中介绍部分有点尴尬\n\n\n\n## 评估\n\nRQ1:相比于其他较好的基线 这个性能在下游任务如何？\n\n列个表 比不上人家的扯一点\n\n\n\nRQ2:三个预训练任务对五个下游任务分别有什么贡献？\n\n——消融实验\n\n有趣的是 删除掉MNG （生成 方法的token）在代码完成和代码修复上性能有所提高：\n\n* MNG是目标自然语言的预训练，而这两项任务都是代码到代码\n\n分析一下 什么任务对什么下游有影响\n\n\n\n**稍微有点水平的问题**\n\nRQ3: 可以利用更多无标记的资料是不是本模型的优点呢？\n\n相较于别的预训练模型，由于它的设计，可以使用无标注数据。更好的性能是不是来自于更多的数据呢？（而不是模型本身厉害？）\n\n在同样的数据集上训练——把它当作无标注的——其实和别的比还算吃亏——也能够取得相对别的模型更好的结果。\n\n可以说是赢两遍了。\n\n\n\nRQ4:微调阶段的数据量对下游任务有什么影响？\n\n虽然越小越坏，但是很小也和别的模型差不多 说明真好\n\n\n\n\n\n## 定性分析与定量分析\n\n定量：志愿者评估，多个样本分类列表个\n\n定性：在哪些任务哪些方面表现好 不好的怎么不好\n\n\n\n# 威胁分析\n\n构造：数据集可能有重复\n\n内部：没调过超参数：所以可能有更好的\n\n外部：只用了CodesearchNet\n\n\n\n# 总结：\n\n我们介绍了SPT-Code，这是一个基于编码器架构的源代码的大型型号。首先，我们为预训练SPT代码设计了三个特定代码的预训练任务。其次，我们提出了一种新的输入表示形式，它是第一个考虑自然语言和AST形式的方法，我们还提出了AST遍历方法的改进版本XSBT。我们的预训练任务和输入表示形式都允许在完全未标记的数据集上预先训练SPT代码。然后，对五个与代码相关的下游任务进行了微调。结果表明，微调SPT代码使其能够在五个与代码相关的下游任务上实现最新性能。消融实验表明，这三个预训练任务对不同的下游任务具有不同程度的影响，AST和自然语言输入也有助于提高SPTCODE的性能。为了促进未来的研究，我们还可以在https://github.com/ nougatca/spt-code上公开提供代码和其他。\n\n\n\n\n\n","slug":"SPT-Code","published":1,"updated":"2022-06-20T13:14:47.373Z","_id":"cl4mr9vdp0008s0w98s1ngzpm","comments":1,"layout":"post","photos":[],"link":"","content":"<p>这是《Sequence-to-Sequence Pre-Training for Learning Source Code Representations》的读书笔记</p>\n<span id=\"more\"></span>\n\n\n\n<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>Pre-trained models 用于代码相关下游任务的应用时的 问题？</p>\n<ol>\n<li>仅用了Pre-trained encoder 但生成任务需要两个部件都预训练</li>\n<li>现在许多Pre-trained model 包括T5，只是简单复用了NL的预训练任务，这要求NL-CODE的corpus 这使得数据受限</li>\n</ol>\n<p>为了应对这两个问题 提出了SPT-Code ，在微调后可以在5个代码相关任务上SOTA</p>\n<p>这是一个seq2seq 预训练模型，通过三个预训练任务使得其能够学习到下面三点，并在下游任务中使用</p>\n<ul>\n<li>代码知识</li>\n<li>对应代码结构</li>\n<li>自然语言描述</li>\n</ul>\n<p>而不需要双语corpus</p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>作者在第一部分提了自监督训练，然后说预训练模型的成功和这个有关系，下面谈预训练模型到软工SE任务的时候认为的问题是：</p>\n<ul>\n<li><p>主流预训练模型仅对encoder搞 ，不够理想</p>\n<p>最有名的encoder也就是BERT吧 也确实就是用了MLM（Masked Language Modeling） 也确实有好多Pre-trained Bert 下面套个任务头或者另一个decoder就开干的……不过这应该算是蛮荒时代了 T5虽然好 但是对一般研究人员来说想改进模型architecture 不是那么容易？</p>\n<ul>\n<li><p>别人的解决：</p>\n<p>T5-learning , TreeBERT 两个工作使得Encoder-Decoder jointly trainded</p>\n</li>\n</ul>\n</li>\n<li><p>这些预训练模型预设输入的是NL-CODE 忽视了代码结构</p>\n<p>为什么呢？因为就是简单偷了NLP的拿来用</p>\n<ul>\n<li><p>别人的解决：</p>\n<p>专门的预训练任务 包括预测数据流图中的边与对齐节点和代码 </p>\n<p>——dataflow 有语义信息而无语法信息（AST）</p>\n</li>\n</ul>\n</li>\n<li><p>而且都假设有严格对齐的双语语料</p>\n<ul>\n<li><p>T5-learning :</p>\n<p>分别处理两种输入，不要求语料库中展示二者的关系</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>—— 没有一个模型能够统一处理这三个问题</p>\n<p>SPT-Code就可以！</p>\n<ul>\n<li>这是一个encoder-decoder共同预训练的模型</li>\n<li>数据实例由CODE,AST,NL三部分构成</li>\n<li>使用方法名和调用此方法的方式作为自然语言描述（以避免对bilingual corpus的依赖）</li>\n</ul>\n<p>方法：</p>\n<p>设计了三种预训练任务，每一种获取一种数据信息</p>\n<ul>\n<li>改进的MASS-用于CODE：遮蔽Seq2Seq恢复</li>\n<li>Code-AST Predict CAP：预测code-AST是否匹配</li>\n<li>Method Name Generation MNG：生成 方法名的 子token</li>\n</ul>\n<p>数据集：</p>\n<p>CodeSearchNet</p>\n<p>贡献：</p>\n<ol>\n<li>提出了SPT-Code预训练模型，可用于分类和生成任务</li>\n<li>使用了线性和简化的AST 第一个使用了NL&amp;AST作为输入对于预训练</li>\n<li>通过输入表示和三个与训练任务使得预训练模型不依赖双语语料库（labeled data)</li>\n<li>用未标注数据库在五个下游任务实现了SOTA</li>\n</ol>\n<h1 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h1><p>架构，输入和预训练任务，微调</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p>类似于BART和T5的典型Transformer</p>\n<p>分类任务和生成任务，模型采用相同的输入：</p>\n<ul>\n<li>分类对encoder和decoder输入相同</li>\n<li>生成采用传统方法</li>\n</ul>\n<img src=\"/2022/05/27/SPT-Code/image-20220527230530594.png\" alt=\"image-20220527230530594\" style=\"zoom:50%;\">\n\n<h2 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h2><img src=\"/2022/05/27/SPT-Code/image-20220527231806850.png\" alt=\"image-20220527231806850\" style=\"zoom:50%;\">\n\n<p>由三部分组成，每一部分[SEP]连接</p>\n<h3 id=\"Code：\"><a href=\"#Code：\" class=\"headerlink\" title=\"Code：\"></a>Code：</h3><p>没有使用笨蛋tokenizer，而是用了stl for Python 或者 antlr for Java,Php.etc 其他的用了NLTK</p>\n<h3 id=\"AST\"><a href=\"#AST\" class=\"headerlink\" title=\"AST\"></a>AST</h3><p>用的Tree-sitter 搞的 AST </p>\n<p> 如何序列化AST?</p>\n<ul>\n<li><p>传统方法：SBT （Structure-Based Traversal)</p>\n<p>比先序遍历之类的更有效，但可能产生过长的序列（可能超过代码三倍长）</p>\n<img src=\"/2022/05/27/SPT-Code/image-20220527232629535.png\" alt=\"image-20220527232629535\" style=\"zoom:50%;\">\n\n<center>\n    一种类似中序遍历的说法 来自那篇论文忘了 反正绝对看过\n</center>\n\n</li>\n<li><p>本文的方法：X-SBT：XML-like SBT</p>\n<p>可以减少超过一半的长度</p>\n<img src=\"/2022/05/27/SPT-Code/image-20220527233143119.png\" alt=\"image-20220527233143119\" style=\"zoom:67%;\">\n\n<p>论文自带的图好看一点 这个创新点……只能说是情理之中，毕竟原来那个也太呆了（作者甚至还装模做样证了一下必然更短）</p>\n<p>为了更短: AST——XSBT时，仅取表达式级别以上节点，放弃终结符</p>\n<img src=\"/2022/05/27/SPT-Code/image-20220527233752649.png\" alt=\"image-20220527233752649\" style=\"zoom:50%;\">\n\n<p><strong>这种优化为可接受的，为什么呢？下面这个说得很漂亮：</strong></p>\n<p>AST中包含了语法信息和词法信息，舍弃掉终结符丢失了词法信息，但之前的token（Input中Code的部分）都是词法单元，所以这个信息是没有丢掉的，因此改进可接受</p>\n</li>\n</ul>\n<h3 id=\"NL\"><a href=\"#NL\" class=\"headerlink\" title=\"NL\"></a>NL</h3><p>难点：从仅有CODE中提取NL</p>\n<p>方法：获取方法名与调用的API序列</p>\n<p>对驼峰和下划线命名掰开</p>\n<p>问题：怎么提取的API序列：从AST里偷出来的？</p>\n<p>——应该就是</p>\n<h2 id=\"预训练任务\"><a href=\"#预训练任务\" class=\"headerlink\" title=\"预训练任务\"></a>预训练任务</h2><p>𝐼𝑛𝑝𝑢𝑡 &#x3D; 𝐶,[SEP],𝐴,[SEP],𝑁 </p>\n<h3 id=\"Code-AST-Prediction\"><a href=\"#Code-AST-Prediction\" class=\"headerlink\" title=\"Code-AST Prediction.\"></a>Code-AST Prediction.</h3><p>这是第一个</p>\n<p>在构建输入𝐼𝑛𝑝𝑢𝑡 时，一半是对应的AST,一半是随机的AST</p>\n<h3 id=\"MASS\"><a href=\"#MASS\" class=\"headerlink\" title=\"MASS\"></a>MASS</h3><p>随机遮蔽C中的一部分，将所有遮蔽的token设置为[MASK]（改进前为对应数量个[MASK])</p>\n<p>根据别人的论文，最大遮蔽长度是C长度l的一半</p>\n<h3 id=\"Method-Name-Generation\"><a href=\"#Method-Name-Generation\" class=\"headerlink\" title=\"Method Name Generation\"></a>Method Name Generation</h3><p>希望可以通过这个任务学到代码的动机</p>\n<p>代码名的词汇和对应代码总结的词汇由高度相关，因此希望通过改善 预测代码名 这一任务提升 代码总结 的能力</p>\n<p>此任务的输入时，从𝐼𝑛𝑝𝑢𝑡中的C扣掉对应token，并在N中去掉前s个token（方法名总在最前），作为输入，试图让decoder输出扣掉的前s个token，即方法名</p>\n<h2 id=\"微调\"><a href=\"#微调\" class=\"headerlink\" title=\"微调\"></a>微调</h2><p>端到端 根据不同任务分成两类，分类或生成，不同任务就缺掉一点输入</p>\n<h1 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h1><h2 id=\"预训练\"><a href=\"#预训练\" class=\"headerlink\" title=\"预训练\"></a>预训练</h2><p>交代了数据集的数据使用，任务顺序，epoches，用的cross-entropy loss和Adam-W，batchsize和显卡（……）</p>\n<p>Tokenizer Encoding 用的BPE对CODE和NL，在预训练data上干过 每个下游任务照用</p>\n<p>预训练任务的任务量都是每个任务几十个Epoches的量级。</p>\n<p>问题：不是都有token了 还tokenize？</p>\n<p>——低级问题，前面的应该是tokenize，这里进行token&#x3D;&gt;input_ids的步骤</p>\n<h2 id=\"下游任务微调\"><a href=\"#下游任务微调\" class=\"headerlink\" title=\"下游任务微调\"></a>下游任务微调</h2><p>介绍了五个任务 其中介绍部分有点尴尬</p>\n<h2 id=\"评估\"><a href=\"#评估\" class=\"headerlink\" title=\"评估\"></a>评估</h2><p>RQ1:相比于其他较好的基线 这个性能在下游任务如何？</p>\n<p>列个表 比不上人家的扯一点</p>\n<p>RQ2:三个预训练任务对五个下游任务分别有什么贡献？</p>\n<p>——消融实验</p>\n<p>有趣的是 删除掉MNG （生成 方法的token）在代码完成和代码修复上性能有所提高：</p>\n<ul>\n<li>MNG是目标自然语言的预训练，而这两项任务都是代码到代码</li>\n</ul>\n<p>分析一下 什么任务对什么下游有影响</p>\n<p><strong>稍微有点水平的问题</strong></p>\n<p>RQ3: 可以利用更多无标记的资料是不是本模型的优点呢？</p>\n<p>相较于别的预训练模型，由于它的设计，可以使用无标注数据。更好的性能是不是来自于更多的数据呢？（而不是模型本身厉害？）</p>\n<p>在同样的数据集上训练——把它当作无标注的——其实和别的比还算吃亏——也能够取得相对别的模型更好的结果。</p>\n<p>可以说是赢两遍了。</p>\n<p>RQ4:微调阶段的数据量对下游任务有什么影响？</p>\n<p>虽然越小越坏，但是很小也和别的模型差不多 说明真好</p>\n<h2 id=\"定性分析与定量分析\"><a href=\"#定性分析与定量分析\" class=\"headerlink\" title=\"定性分析与定量分析\"></a>定性分析与定量分析</h2><p>定量：志愿者评估，多个样本分类列表个</p>\n<p>定性：在哪些任务哪些方面表现好 不好的怎么不好</p>\n<h1 id=\"威胁分析\"><a href=\"#威胁分析\" class=\"headerlink\" title=\"威胁分析\"></a>威胁分析</h1><p>构造：数据集可能有重复</p>\n<p>内部：没调过超参数：所以可能有更好的</p>\n<p>外部：只用了CodesearchNet</p>\n<h1 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h1><p>我们介绍了SPT-Code，这是一个基于编码器架构的源代码的大型型号。首先，我们为预训练SPT代码设计了三个特定代码的预训练任务。其次，我们提出了一种新的输入表示形式，它是第一个考虑自然语言和AST形式的方法，我们还提出了AST遍历方法的改进版本XSBT。我们的预训练任务和输入表示形式都允许在完全未标记的数据集上预先训练SPT代码。然后，对五个与代码相关的下游任务进行了微调。结果表明，微调SPT代码使其能够在五个与代码相关的下游任务上实现最新性能。消融实验表明，这三个预训练任务对不同的下游任务具有不同程度的影响，AST和自然语言输入也有助于提高SPTCODE的性能。为了促进未来的研究，我们还可以在<a href=\"https://github.com/\">https://github.com/</a> nougatca&#x2F;spt-code上公开提供代码和其他。</p>\n","site":{"data":{}},"excerpt":"<p>这是《Sequence-to-Sequence Pre-Training for Learning Source Code Representations》的读书笔记</p>","more":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>Pre-trained models 用于代码相关下游任务的应用时的 问题？</p>\n<ol>\n<li>仅用了Pre-trained encoder 但生成任务需要两个部件都预训练</li>\n<li>现在许多Pre-trained model 包括T5，只是简单复用了NL的预训练任务，这要求NL-CODE的corpus 这使得数据受限</li>\n</ol>\n<p>为了应对这两个问题 提出了SPT-Code ，在微调后可以在5个代码相关任务上SOTA</p>\n<p>这是一个seq2seq 预训练模型，通过三个预训练任务使得其能够学习到下面三点，并在下游任务中使用</p>\n<ul>\n<li>代码知识</li>\n<li>对应代码结构</li>\n<li>自然语言描述</li>\n</ul>\n<p>而不需要双语corpus</p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>作者在第一部分提了自监督训练，然后说预训练模型的成功和这个有关系，下面谈预训练模型到软工SE任务的时候认为的问题是：</p>\n<ul>\n<li><p>主流预训练模型仅对encoder搞 ，不够理想</p>\n<p>最有名的encoder也就是BERT吧 也确实就是用了MLM（Masked Language Modeling） 也确实有好多Pre-trained Bert 下面套个任务头或者另一个decoder就开干的……不过这应该算是蛮荒时代了 T5虽然好 但是对一般研究人员来说想改进模型architecture 不是那么容易？</p>\n<ul>\n<li><p>别人的解决：</p>\n<p>T5-learning , TreeBERT 两个工作使得Encoder-Decoder jointly trainded</p>\n</li>\n</ul>\n</li>\n<li><p>这些预训练模型预设输入的是NL-CODE 忽视了代码结构</p>\n<p>为什么呢？因为就是简单偷了NLP的拿来用</p>\n<ul>\n<li><p>别人的解决：</p>\n<p>专门的预训练任务 包括预测数据流图中的边与对齐节点和代码 </p>\n<p>——dataflow 有语义信息而无语法信息（AST）</p>\n</li>\n</ul>\n</li>\n<li><p>而且都假设有严格对齐的双语语料</p>\n<ul>\n<li><p>T5-learning :</p>\n<p>分别处理两种输入，不要求语料库中展示二者的关系</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>—— 没有一个模型能够统一处理这三个问题</p>\n<p>SPT-Code就可以！</p>\n<ul>\n<li>这是一个encoder-decoder共同预训练的模型</li>\n<li>数据实例由CODE,AST,NL三部分构成</li>\n<li>使用方法名和调用此方法的方式作为自然语言描述（以避免对bilingual corpus的依赖）</li>\n</ul>\n<p>方法：</p>\n<p>设计了三种预训练任务，每一种获取一种数据信息</p>\n<ul>\n<li>改进的MASS-用于CODE：遮蔽Seq2Seq恢复</li>\n<li>Code-AST Predict CAP：预测code-AST是否匹配</li>\n<li>Method Name Generation MNG：生成 方法名的 子token</li>\n</ul>\n<p>数据集：</p>\n<p>CodeSearchNet</p>\n<p>贡献：</p>\n<ol>\n<li>提出了SPT-Code预训练模型，可用于分类和生成任务</li>\n<li>使用了线性和简化的AST 第一个使用了NL&amp;AST作为输入对于预训练</li>\n<li>通过输入表示和三个与训练任务使得预训练模型不依赖双语语料库（labeled data)</li>\n<li>用未标注数据库在五个下游任务实现了SOTA</li>\n</ol>\n<h1 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h1><p>架构，输入和预训练任务，微调</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><p>类似于BART和T5的典型Transformer</p>\n<p>分类任务和生成任务，模型采用相同的输入：</p>\n<ul>\n<li>分类对encoder和decoder输入相同</li>\n<li>生成采用传统方法</li>\n</ul>\n<img src=\"/2022/05/27/SPT-Code/image-20220527230530594.png\" alt=\"image-20220527230530594\" style=\"zoom:50%;\">\n\n<h2 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h2><img src=\"/2022/05/27/SPT-Code/image-20220527231806850.png\" alt=\"image-20220527231806850\" style=\"zoom:50%;\">\n\n<p>由三部分组成，每一部分[SEP]连接</p>\n<h3 id=\"Code：\"><a href=\"#Code：\" class=\"headerlink\" title=\"Code：\"></a>Code：</h3><p>没有使用笨蛋tokenizer，而是用了stl for Python 或者 antlr for Java,Php.etc 其他的用了NLTK</p>\n<h3 id=\"AST\"><a href=\"#AST\" class=\"headerlink\" title=\"AST\"></a>AST</h3><p>用的Tree-sitter 搞的 AST </p>\n<p> 如何序列化AST?</p>\n<ul>\n<li><p>传统方法：SBT （Structure-Based Traversal)</p>\n<p>比先序遍历之类的更有效，但可能产生过长的序列（可能超过代码三倍长）</p>\n<img src=\"/2022/05/27/SPT-Code/image-20220527232629535.png\" alt=\"image-20220527232629535\" style=\"zoom:50%;\">\n\n<center>\n    一种类似中序遍历的说法 来自那篇论文忘了 反正绝对看过\n</center>\n\n</li>\n<li><p>本文的方法：X-SBT：XML-like SBT</p>\n<p>可以减少超过一半的长度</p>\n<img src=\"/2022/05/27/SPT-Code/image-20220527233143119.png\" alt=\"image-20220527233143119\" style=\"zoom:67%;\">\n\n<p>论文自带的图好看一点 这个创新点……只能说是情理之中，毕竟原来那个也太呆了（作者甚至还装模做样证了一下必然更短）</p>\n<p>为了更短: AST——XSBT时，仅取表达式级别以上节点，放弃终结符</p>\n<img src=\"/2022/05/27/SPT-Code/image-20220527233752649.png\" alt=\"image-20220527233752649\" style=\"zoom:50%;\">\n\n<p><strong>这种优化为可接受的，为什么呢？下面这个说得很漂亮：</strong></p>\n<p>AST中包含了语法信息和词法信息，舍弃掉终结符丢失了词法信息，但之前的token（Input中Code的部分）都是词法单元，所以这个信息是没有丢掉的，因此改进可接受</p>\n</li>\n</ul>\n<h3 id=\"NL\"><a href=\"#NL\" class=\"headerlink\" title=\"NL\"></a>NL</h3><p>难点：从仅有CODE中提取NL</p>\n<p>方法：获取方法名与调用的API序列</p>\n<p>对驼峰和下划线命名掰开</p>\n<p>问题：怎么提取的API序列：从AST里偷出来的？</p>\n<p>——应该就是</p>\n<h2 id=\"预训练任务\"><a href=\"#预训练任务\" class=\"headerlink\" title=\"预训练任务\"></a>预训练任务</h2><p>𝐼𝑛𝑝𝑢𝑡 &#x3D; 𝐶,[SEP],𝐴,[SEP],𝑁 </p>\n<h3 id=\"Code-AST-Prediction\"><a href=\"#Code-AST-Prediction\" class=\"headerlink\" title=\"Code-AST Prediction.\"></a>Code-AST Prediction.</h3><p>这是第一个</p>\n<p>在构建输入𝐼𝑛𝑝𝑢𝑡 时，一半是对应的AST,一半是随机的AST</p>\n<h3 id=\"MASS\"><a href=\"#MASS\" class=\"headerlink\" title=\"MASS\"></a>MASS</h3><p>随机遮蔽C中的一部分，将所有遮蔽的token设置为[MASK]（改进前为对应数量个[MASK])</p>\n<p>根据别人的论文，最大遮蔽长度是C长度l的一半</p>\n<h3 id=\"Method-Name-Generation\"><a href=\"#Method-Name-Generation\" class=\"headerlink\" title=\"Method Name Generation\"></a>Method Name Generation</h3><p>希望可以通过这个任务学到代码的动机</p>\n<p>代码名的词汇和对应代码总结的词汇由高度相关，因此希望通过改善 预测代码名 这一任务提升 代码总结 的能力</p>\n<p>此任务的输入时，从𝐼𝑛𝑝𝑢𝑡中的C扣掉对应token，并在N中去掉前s个token（方法名总在最前），作为输入，试图让decoder输出扣掉的前s个token，即方法名</p>\n<h2 id=\"微调\"><a href=\"#微调\" class=\"headerlink\" title=\"微调\"></a>微调</h2><p>端到端 根据不同任务分成两类，分类或生成，不同任务就缺掉一点输入</p>\n<h1 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h1><h2 id=\"预训练\"><a href=\"#预训练\" class=\"headerlink\" title=\"预训练\"></a>预训练</h2><p>交代了数据集的数据使用，任务顺序，epoches，用的cross-entropy loss和Adam-W，batchsize和显卡（……）</p>\n<p>Tokenizer Encoding 用的BPE对CODE和NL，在预训练data上干过 每个下游任务照用</p>\n<p>预训练任务的任务量都是每个任务几十个Epoches的量级。</p>\n<p>问题：不是都有token了 还tokenize？</p>\n<p>——低级问题，前面的应该是tokenize，这里进行token&#x3D;&gt;input_ids的步骤</p>\n<h2 id=\"下游任务微调\"><a href=\"#下游任务微调\" class=\"headerlink\" title=\"下游任务微调\"></a>下游任务微调</h2><p>介绍了五个任务 其中介绍部分有点尴尬</p>\n<h2 id=\"评估\"><a href=\"#评估\" class=\"headerlink\" title=\"评估\"></a>评估</h2><p>RQ1:相比于其他较好的基线 这个性能在下游任务如何？</p>\n<p>列个表 比不上人家的扯一点</p>\n<p>RQ2:三个预训练任务对五个下游任务分别有什么贡献？</p>\n<p>——消融实验</p>\n<p>有趣的是 删除掉MNG （生成 方法的token）在代码完成和代码修复上性能有所提高：</p>\n<ul>\n<li>MNG是目标自然语言的预训练，而这两项任务都是代码到代码</li>\n</ul>\n<p>分析一下 什么任务对什么下游有影响</p>\n<p><strong>稍微有点水平的问题</strong></p>\n<p>RQ3: 可以利用更多无标记的资料是不是本模型的优点呢？</p>\n<p>相较于别的预训练模型，由于它的设计，可以使用无标注数据。更好的性能是不是来自于更多的数据呢？（而不是模型本身厉害？）</p>\n<p>在同样的数据集上训练——把它当作无标注的——其实和别的比还算吃亏——也能够取得相对别的模型更好的结果。</p>\n<p>可以说是赢两遍了。</p>\n<p>RQ4:微调阶段的数据量对下游任务有什么影响？</p>\n<p>虽然越小越坏，但是很小也和别的模型差不多 说明真好</p>\n<h2 id=\"定性分析与定量分析\"><a href=\"#定性分析与定量分析\" class=\"headerlink\" title=\"定性分析与定量分析\"></a>定性分析与定量分析</h2><p>定量：志愿者评估，多个样本分类列表个</p>\n<p>定性：在哪些任务哪些方面表现好 不好的怎么不好</p>\n<h1 id=\"威胁分析\"><a href=\"#威胁分析\" class=\"headerlink\" title=\"威胁分析\"></a>威胁分析</h1><p>构造：数据集可能有重复</p>\n<p>内部：没调过超参数：所以可能有更好的</p>\n<p>外部：只用了CodesearchNet</p>\n<h1 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h1><p>我们介绍了SPT-Code，这是一个基于编码器架构的源代码的大型型号。首先，我们为预训练SPT代码设计了三个特定代码的预训练任务。其次，我们提出了一种新的输入表示形式，它是第一个考虑自然语言和AST形式的方法，我们还提出了AST遍历方法的改进版本XSBT。我们的预训练任务和输入表示形式都允许在完全未标记的数据集上预先训练SPT代码。然后，对五个与代码相关的下游任务进行了微调。结果表明，微调SPT代码使其能够在五个与代码相关的下游任务上实现最新性能。消融实验表明，这三个预训练任务对不同的下游任务具有不同程度的影响，AST和自然语言输入也有助于提高SPTCODE的性能。为了促进未来的研究，我们还可以在<a href=\"https://github.com/\">https://github.com/</a> nougatca&#x2F;spt-code上公开提供代码和其他。</p>"},{"title":"火柴","date":"2022-05-28T18:20:04.000Z","_content":"我在[^6]水中桥下[^1] 饮酒[^2]/~~忘相泉涸[^4]前日的红烛[^5]泪眼[^3]~~红烛淡忘镜中的泪眼\n\n[^1]:「尾生與女子期於梁下，女子不來，水至不去，抱樑柱而死。」《莊子·盜跖》\n[^2]:  「夢飲酒者，旦而哭泣；夢哭泣者，旦而田獵。方其夢也，不知其夢也。」《莊子·齊物論》\n[^3]: 「文侯與虞人期獵。是日，飲酒樂，天雨。文侯將出，左右曰：「今日飲酒樂，天又雨，公將焉之？」文侯曰：「吾與虞人期獵，雖樂，豈可不一會期哉！」乃往，身自罷之。」《戰國策·魏策》\n[^4]: 「泉涸，魚相與處於陸，相呴以溼，相濡以沫，不如相忘於江湖。」《莊子·大宗師》\n\n[^5]: 「蠟炬成灰淚始幹」 李商隐\n[^6]: 火柴梗快要烧完的时候，会因为火焰过分接近而忍不住松手\n\n\n\n自己写完还解诗的人肯定是天下第一无聊 但这只不过是记录灵感媾和时的一些脉络和取舍。\n<!--more-->\n\n\n***\n\n2022/5/30日凌晨睡不着床上对后半句做了修正\n\n第二天起来看前天写得也太迫真了 简直就是笨蛋版本李商隐\n\n当时是怎么想的呢？「忘相」是什么表达？生怕别人看不出来是你直接从庄子里偷来的？「泉涸」同理，太白太直了 反而失去了解读空间。「前日」也不明所以的。都要删掉。「红烛泪眼」是核心意象要留下来。\n\n想要留下来的是什么呢？遗忘肯定是要有的，这是我给出的解答。互相也是要有的，起源就是由防风火柴想到的尾生抱柱抛出的一问。「红烛泪眼」没法共轭，还是拆开好了。\n\n互相的话 就用镜子好了。破妄，吊诡，空间的拓展却又重复，自反中带有异质性。很好。\n\n「红烛在镜中总是泪眼」？当时还开心的把手机翻出来赶紧记下，记完想想又觉得不好 啰啰嗦嗦的。\n\n「红烛向镜中抛去泪眼」？我很喜欢这个动作带有的力量感，和伴随而来的主体性。用什么迎接你？以眼泪，以沉默。这是有力量的沉默。但是汉语还是半通不通的 忘记也没了。不好。\n\n「忘记」这个字其实很好，自反又偏义，但是口语中用得太多了 读来感觉不到妙处 不好。\n\n我想，烛火燃烧时上腾的青烟，蒸腾的雾气凝结成雨，落下化为沙尘，恰好就有一种复调式的演出效果。水汽也好，腾烟也好，怎么放在这里处理”忘“这个要素呢？想到了溶解，融化，但都用不好。这里卡了很久没想出来。\n\n灵光一闪，就用「淡忘」。「淡」字自己就好像是拿来给水墨化开的，要是到token级别就是又有水又有火的自反，不管是前句的湖中还是镜子都能超距作用。「淡忘」本来不是什么僻词，但放在这里就妙得没话说。\n\n「红烛淡忘镜中的泪眼」，真好。\n\n「我」「饮酒」，「烛」「忘眼」。好像比兴一样的氛围，又构成了复调的演奏。「水」与「镜」，「泪」与「眼」，几乎每一个元素都能够进行笛卡尔式呼应。比兴之中，阅读顺序的先后带来的时序性还为文本增添了并列以外的递进因素，自问自答。很好。我很喜欢。\n\n如果说昨天是向义山一样堆叠典故，这次就是处理意象了，也是很好玩呐。\n\n下面又试着加点东西。一方面是平衡语感。这两句佶屈聱牙，像极了祭祀用的七言律诗，但是要是能像冯君一样，神神叨叨念完“长剑归来乎，”，令人不容小觑，立马接上一句“食无鱼”产生节目效果。那就可以说是非常成功了。\n\n此外，也和我想要追求的吊诡氛围有点差异。水中饮酒还有镜子，好像是月光下的水晶湖一样，太明亮通透了些/\n\n加什么呢？四个字的好。「烟波浩渺」？我想到洞庭湖，蹭蹭湘君的隐喻正好在调上。「烟涛微茫」？直接偷过来好像也不坏。像是舞台布景的话，很明白的小舞台放在巨大的烟幕里，也是那个意思。\n\n不过怎么放怎么感觉不妙，况且下来也不知怎么接手。先这么放着好了。","source":"_posts/火柴.md","raw":"---\ntitle: 火柴\ndate: 2022-05-29 02:20:04\ntags:\n- Poem\n- Self\ncategories:\n- Metaphysics\n---\n我在[^6]水中桥下[^1] 饮酒[^2]/~~忘相泉涸[^4]前日的红烛[^5]泪眼[^3]~~红烛淡忘镜中的泪眼\n\n[^1]:「尾生與女子期於梁下，女子不來，水至不去，抱樑柱而死。」《莊子·盜跖》\n[^2]:  「夢飲酒者，旦而哭泣；夢哭泣者，旦而田獵。方其夢也，不知其夢也。」《莊子·齊物論》\n[^3]: 「文侯與虞人期獵。是日，飲酒樂，天雨。文侯將出，左右曰：「今日飲酒樂，天又雨，公將焉之？」文侯曰：「吾與虞人期獵，雖樂，豈可不一會期哉！」乃往，身自罷之。」《戰國策·魏策》\n[^4]: 「泉涸，魚相與處於陸，相呴以溼，相濡以沫，不如相忘於江湖。」《莊子·大宗師》\n\n[^5]: 「蠟炬成灰淚始幹」 李商隐\n[^6]: 火柴梗快要烧完的时候，会因为火焰过分接近而忍不住松手\n\n\n\n自己写完还解诗的人肯定是天下第一无聊 但这只不过是记录灵感媾和时的一些脉络和取舍。\n<!--more-->\n\n\n***\n\n2022/5/30日凌晨睡不着床上对后半句做了修正\n\n第二天起来看前天写得也太迫真了 简直就是笨蛋版本李商隐\n\n当时是怎么想的呢？「忘相」是什么表达？生怕别人看不出来是你直接从庄子里偷来的？「泉涸」同理，太白太直了 反而失去了解读空间。「前日」也不明所以的。都要删掉。「红烛泪眼」是核心意象要留下来。\n\n想要留下来的是什么呢？遗忘肯定是要有的，这是我给出的解答。互相也是要有的，起源就是由防风火柴想到的尾生抱柱抛出的一问。「红烛泪眼」没法共轭，还是拆开好了。\n\n互相的话 就用镜子好了。破妄，吊诡，空间的拓展却又重复，自反中带有异质性。很好。\n\n「红烛在镜中总是泪眼」？当时还开心的把手机翻出来赶紧记下，记完想想又觉得不好 啰啰嗦嗦的。\n\n「红烛向镜中抛去泪眼」？我很喜欢这个动作带有的力量感，和伴随而来的主体性。用什么迎接你？以眼泪，以沉默。这是有力量的沉默。但是汉语还是半通不通的 忘记也没了。不好。\n\n「忘记」这个字其实很好，自反又偏义，但是口语中用得太多了 读来感觉不到妙处 不好。\n\n我想，烛火燃烧时上腾的青烟，蒸腾的雾气凝结成雨，落下化为沙尘，恰好就有一种复调式的演出效果。水汽也好，腾烟也好，怎么放在这里处理”忘“这个要素呢？想到了溶解，融化，但都用不好。这里卡了很久没想出来。\n\n灵光一闪，就用「淡忘」。「淡」字自己就好像是拿来给水墨化开的，要是到token级别就是又有水又有火的自反，不管是前句的湖中还是镜子都能超距作用。「淡忘」本来不是什么僻词，但放在这里就妙得没话说。\n\n「红烛淡忘镜中的泪眼」，真好。\n\n「我」「饮酒」，「烛」「忘眼」。好像比兴一样的氛围，又构成了复调的演奏。「水」与「镜」，「泪」与「眼」，几乎每一个元素都能够进行笛卡尔式呼应。比兴之中，阅读顺序的先后带来的时序性还为文本增添了并列以外的递进因素，自问自答。很好。我很喜欢。\n\n如果说昨天是向义山一样堆叠典故，这次就是处理意象了，也是很好玩呐。\n\n下面又试着加点东西。一方面是平衡语感。这两句佶屈聱牙，像极了祭祀用的七言律诗，但是要是能像冯君一样，神神叨叨念完“长剑归来乎，”，令人不容小觑，立马接上一句“食无鱼”产生节目效果。那就可以说是非常成功了。\n\n此外，也和我想要追求的吊诡氛围有点差异。水中饮酒还有镜子，好像是月光下的水晶湖一样，太明亮通透了些/\n\n加什么呢？四个字的好。「烟波浩渺」？我想到洞庭湖，蹭蹭湘君的隐喻正好在调上。「烟涛微茫」？直接偷过来好像也不坏。像是舞台布景的话，很明白的小舞台放在巨大的烟幕里，也是那个意思。\n\n不过怎么放怎么感觉不妙，况且下来也不知怎么接手。先这么放着好了。","slug":"火柴","published":1,"updated":"2022-06-20T11:16:09.630Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl4mr9vdq0009s0w9f2nmdps5","content":"<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><p>我在<sup id=\"fnref:6\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"火柴梗快要烧完的时候，会因为火焰过分接近而忍不住松手\">6</span></a></sup>水中桥下<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"「尾生與女子期於梁下，女子不來，水至不去，抱樑柱而死。」《莊子·盜跖》\n\">1</span></a></sup> 饮酒<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\" 「夢飲酒者，旦而哭泣；夢哭泣者，旦而田獵。方其夢也，不知其夢也。」《莊子·齊物論》\n\">2</span></a></sup>&#x2F;<del>忘相泉涸<sup id=\"fnref:4\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"「泉涸，魚相與處於陸，相呴以溼，相濡以沫，不如相忘於江湖。」《莊子·大宗師》\">4</span></a></sup>前日的红烛<sup id=\"fnref:5\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"「蠟炬成灰淚始幹」 李商隐\n\">5</span></a></sup>泪眼<sup id=\"fnref:3\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"「文侯與虞人期獵。是日，飲酒樂，天雨。文侯將出，左右曰：「今日飲酒樂，天又雨，公將焉之？」文侯曰：「吾與虞人期獵，雖樂，豈可不一會期哉！」乃往，身自罷之。」《戰國策·魏策》\n\">3</span></a></sup></del>红烛淡忘镜中的泪眼</p>\n<p>自己写完还解诗的人肯定是天下第一无聊 但这只不过是记录灵感媾和时的一些脉络和取舍。</p>\n<span id=\"more\"></span>\n\n\n<hr>\n<p>2022&#x2F;5&#x2F;30日凌晨睡不着床上对后半句做了修正</p>\n<p>第二天起来看前天写得也太迫真了 简直就是笨蛋版本李商隐</p>\n<p>当时是怎么想的呢？「忘相」是什么表达？生怕别人看不出来是你直接从庄子里偷来的？「泉涸」同理，太白太直了 反而失去了解读空间。「前日」也不明所以的。都要删掉。「红烛泪眼」是核心意象要留下来。</p>\n<p>想要留下来的是什么呢？遗忘肯定是要有的，这是我给出的解答。互相也是要有的，起源就是由防风火柴想到的尾生抱柱抛出的一问。「红烛泪眼」没法共轭，还是拆开好了。</p>\n<p>互相的话 就用镜子好了。破妄，吊诡，空间的拓展却又重复，自反中带有异质性。很好。</p>\n<p>「红烛在镜中总是泪眼」？当时还开心的把手机翻出来赶紧记下，记完想想又觉得不好 啰啰嗦嗦的。</p>\n<p>「红烛向镜中抛去泪眼」？我很喜欢这个动作带有的力量感，和伴随而来的主体性。用什么迎接你？以眼泪，以沉默。这是有力量的沉默。但是汉语还是半通不通的 忘记也没了。不好。</p>\n<p>「忘记」这个字其实很好，自反又偏义，但是口语中用得太多了 读来感觉不到妙处 不好。</p>\n<p>我想，烛火燃烧时上腾的青烟，蒸腾的雾气凝结成雨，落下化为沙尘，恰好就有一种复调式的演出效果。水汽也好，腾烟也好，怎么放在这里处理”忘“这个要素呢？想到了溶解，融化，但都用不好。这里卡了很久没想出来。</p>\n<p>灵光一闪，就用「淡忘」。「淡」字自己就好像是拿来给水墨化开的，要是到token级别就是又有水又有火的自反，不管是前句的湖中还是镜子都能超距作用。「淡忘」本来不是什么僻词，但放在这里就妙得没话说。</p>\n<p>「红烛淡忘镜中的泪眼」，真好。</p>\n<p>「我」「饮酒」，「烛」「忘眼」。好像比兴一样的氛围，又构成了复调的演奏。「水」与「镜」，「泪」与「眼」，几乎每一个元素都能够进行笛卡尔式呼应。比兴之中，阅读顺序的先后带来的时序性还为文本增添了并列以外的递进因素，自问自答。很好。我很喜欢。</p>\n<p>如果说昨天是向义山一样堆叠典故，这次就是处理意象了，也是很好玩呐。</p>\n<p>下面又试着加点东西。一方面是平衡语感。这两句佶屈聱牙，像极了祭祀用的七言律诗，但是要是能像冯君一样，神神叨叨念完“长剑归来乎，”，令人不容小觑，立马接上一句“食无鱼”产生节目效果。那就可以说是非常成功了。</p>\n<p>此外，也和我想要追求的吊诡氛围有点差异。水中饮酒还有镜子，好像是月光下的水晶湖一样，太明亮通透了些&#x2F;</p>\n<p>加什么呢？四个字的好。「烟波浩渺」？我想到洞庭湖，蹭蹭湘君的隐喻正好在调上。「烟涛微茫」？直接偷过来好像也不坏。像是舞台布景的话，很明白的小舞台放在巨大的烟幕里，也是那个意思。</p>\n<p>不过怎么放怎么感觉不妙，况且下来也不知怎么接手。先这么放着好了。<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「尾生與女子期於梁下，女子不來，水至不去，抱樑柱而死。」《莊子·盜跖》<a href=\"#fnref:1\" rev=\"footnote\">↩</a></span></li><li id=\"fn:2\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">2.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「夢飲酒者，旦而哭泣；夢哭泣者，旦而田獵。方其夢也，不知其夢也。」《莊子·齊物論》<a href=\"#fnref:2\" rev=\"footnote\">↩</a></span></li><li id=\"fn:3\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">3.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「文侯與虞人期獵。是日，飲酒樂，天雨。文侯將出，左右曰：「今日飲酒樂，天又雨，公將焉之？」文侯曰：「吾與虞人期獵，雖樂，豈可不一會期哉！」乃往，身自罷之。」《戰國策·魏策》<a href=\"#fnref:3\" rev=\"footnote\">↩</a></span></li><li id=\"fn:4\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">4.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「泉涸，魚相與處於陸，相呴以溼，相濡以沫，不如相忘於江湖。」《莊子·大宗師》<a href=\"#fnref:4\" rev=\"footnote\">↩</a></span></li><li id=\"fn:5\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">5.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「蠟炬成灰淚始幹」 李商隐<a href=\"#fnref:5\" rev=\"footnote\">↩</a></span></li><li id=\"fn:6\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">6.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">火柴梗快要烧完的时候，会因为火焰过分接近而忍不住松手<a href=\"#fnref:6\" rev=\"footnote\">↩</a></span></li></ol></div></div></p>\n","site":{"data":{}},"excerpt":"<p>我在<sup id=\"fnref:6\"><a href=\"#fn:6\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"火柴梗快要烧完的时候，会因为火焰过分接近而忍不住松手\">6</span></a></sup>水中桥下<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"「尾生與女子期於梁下，女子不來，水至不去，抱樑柱而死。」《莊子·盜跖》\n\">1</span></a></sup> 饮酒<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\" 「夢飲酒者，旦而哭泣；夢哭泣者，旦而田獵。方其夢也，不知其夢也。」《莊子·齊物論》\n\">2</span></a></sup>&#x2F;<del>忘相泉涸<sup id=\"fnref:4\"><a href=\"#fn:4\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"「泉涸，魚相與處於陸，相呴以溼，相濡以沫，不如相忘於江湖。」《莊子·大宗師》\">4</span></a></sup>前日的红烛<sup id=\"fnref:5\"><a href=\"#fn:5\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"「蠟炬成灰淚始幹」 李商隐\n\">5</span></a></sup>泪眼<sup id=\"fnref:3\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--error hint--medium hint--rounded hint--bounce\" aria-label=\"「文侯與虞人期獵。是日，飲酒樂，天雨。文侯將出，左右曰：「今日飲酒樂，天又雨，公將焉之？」文侯曰：「吾與虞人期獵，雖樂，豈可不一會期哉！」乃往，身自罷之。」《戰國策·魏策》\n\">3</span></a></sup></del>红烛淡忘镜中的泪眼</p>\n<p>自己写完还解诗的人肯定是天下第一无聊 但这只不过是记录灵感媾和时的一些脉络和取舍。</p>","more":"<hr>\n<p>2022&#x2F;5&#x2F;30日凌晨睡不着床上对后半句做了修正</p>\n<p>第二天起来看前天写得也太迫真了 简直就是笨蛋版本李商隐</p>\n<p>当时是怎么想的呢？「忘相」是什么表达？生怕别人看不出来是你直接从庄子里偷来的？「泉涸」同理，太白太直了 反而失去了解读空间。「前日」也不明所以的。都要删掉。「红烛泪眼」是核心意象要留下来。</p>\n<p>想要留下来的是什么呢？遗忘肯定是要有的，这是我给出的解答。互相也是要有的，起源就是由防风火柴想到的尾生抱柱抛出的一问。「红烛泪眼」没法共轭，还是拆开好了。</p>\n<p>互相的话 就用镜子好了。破妄，吊诡，空间的拓展却又重复，自反中带有异质性。很好。</p>\n<p>「红烛在镜中总是泪眼」？当时还开心的把手机翻出来赶紧记下，记完想想又觉得不好 啰啰嗦嗦的。</p>\n<p>「红烛向镜中抛去泪眼」？我很喜欢这个动作带有的力量感，和伴随而来的主体性。用什么迎接你？以眼泪，以沉默。这是有力量的沉默。但是汉语还是半通不通的 忘记也没了。不好。</p>\n<p>「忘记」这个字其实很好，自反又偏义，但是口语中用得太多了 读来感觉不到妙处 不好。</p>\n<p>我想，烛火燃烧时上腾的青烟，蒸腾的雾气凝结成雨，落下化为沙尘，恰好就有一种复调式的演出效果。水汽也好，腾烟也好，怎么放在这里处理”忘“这个要素呢？想到了溶解，融化，但都用不好。这里卡了很久没想出来。</p>\n<p>灵光一闪，就用「淡忘」。「淡」字自己就好像是拿来给水墨化开的，要是到token级别就是又有水又有火的自反，不管是前句的湖中还是镜子都能超距作用。「淡忘」本来不是什么僻词，但放在这里就妙得没话说。</p>\n<p>「红烛淡忘镜中的泪眼」，真好。</p>\n<p>「我」「饮酒」，「烛」「忘眼」。好像比兴一样的氛围，又构成了复调的演奏。「水」与「镜」，「泪」与「眼」，几乎每一个元素都能够进行笛卡尔式呼应。比兴之中，阅读顺序的先后带来的时序性还为文本增添了并列以外的递进因素，自问自答。很好。我很喜欢。</p>\n<p>如果说昨天是向义山一样堆叠典故，这次就是处理意象了，也是很好玩呐。</p>\n<p>下面又试着加点东西。一方面是平衡语感。这两句佶屈聱牙，像极了祭祀用的七言律诗，但是要是能像冯君一样，神神叨叨念完“长剑归来乎，”，令人不容小觑，立马接上一句“食无鱼”产生节目效果。那就可以说是非常成功了。</p>\n<p>此外，也和我想要追求的吊诡氛围有点差异。水中饮酒还有镜子，好像是月光下的水晶湖一样，太明亮通透了些&#x2F;</p>\n<p>加什么呢？四个字的好。「烟波浩渺」？我想到洞庭湖，蹭蹭湘君的隐喻正好在调上。「烟涛微茫」？直接偷过来好像也不坏。像是舞台布景的话，很明白的小舞台放在巨大的烟幕里，也是那个意思。</p>\n<p>不过怎么放怎么感觉不妙，况且下来也不知怎么接手。先这么放着好了。<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol style=\"list-style: none; padding-left: 0; margin-left: 40px\"><li id=\"fn:1\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">1.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「尾生與女子期於梁下，女子不來，水至不去，抱樑柱而死。」《莊子·盜跖》<a href=\"#fnref:1\" rev=\"footnote\">↩</a></span></li><li id=\"fn:2\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">2.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「夢飲酒者，旦而哭泣；夢哭泣者，旦而田獵。方其夢也，不知其夢也。」《莊子·齊物論》<a href=\"#fnref:2\" rev=\"footnote\">↩</a></span></li><li id=\"fn:3\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">3.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「文侯與虞人期獵。是日，飲酒樂，天雨。文侯將出，左右曰：「今日飲酒樂，天又雨，公將焉之？」文侯曰：「吾與虞人期獵，雖樂，豈可不一會期哉！」乃往，身自罷之。」《戰國策·魏策》<a href=\"#fnref:3\" rev=\"footnote\">↩</a></span></li><li id=\"fn:4\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">4.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「泉涸，魚相與處於陸，相呴以溼，相濡以沫，不如相忘於江湖。」《莊子·大宗師》<a href=\"#fnref:4\" rev=\"footnote\">↩</a></span></li><li id=\"fn:5\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">5.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">「蠟炬成灰淚始幹」 李商隐<a href=\"#fnref:5\" rev=\"footnote\">↩</a></span></li><li id=\"fn:6\"><span style=\"display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px\">6.</span><span style=\"display: inline-block; vertical-align: top; margin-left: 10px;\">火柴梗快要烧完的时候，会因为火焰过分接近而忍不住松手<a href=\"#fnref:6\" rev=\"footnote\">↩</a></span></li></ol></div></div></p>"}],"PostAsset":[{"_id":"source/_posts/testpic/image-20220523211852621.png","slug":"image-20220523211852621.png","post":"cl4mr9vdo0007s0w9g4fd91zy","modified":0,"renderable":0},{"_id":"source/_posts/testpic/image-20220524021029166.png","slug":"image-20220524021029166.png","post":"cl4mr9vdo0007s0w9g4fd91zy","modified":0,"renderable":0},{"_id":"source/_posts/SPT-Code/image-20220527230530594.png","slug":"image-20220527230530594.png","post":"cl4mr9vdp0008s0w98s1ngzpm","modified":0,"renderable":0},{"_id":"source/_posts/SPT-Code/image-20220527231806850.png","slug":"image-20220527231806850.png","post":"cl4mr9vdp0008s0w98s1ngzpm","modified":0,"renderable":0},{"_id":"source/_posts/SPT-Code/image-20220527232629535.png","slug":"image-20220527232629535.png","post":"cl4mr9vdp0008s0w98s1ngzpm","modified":0,"renderable":0},{"_id":"source/_posts/SPT-Code/image-20220527233143119.png","slug":"image-20220527233143119.png","post":"cl4mr9vdp0008s0w98s1ngzpm","modified":0,"renderable":0},{"_id":"source/_posts/SPT-Code/image-20220527233752649.png","slug":"image-20220527233752649.png","post":"cl4mr9vdp0008s0w98s1ngzpm","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cl4mr9vdg0001s0w996o99a6j","category_id":"cl4mr9vdm0004s0w9hdxl1tua","_id":"cl4mr9vds000cs0w9ecv789a2"},{"post_id":"cl4mr9vdq0009s0w9f2nmdps5","category_id":"cl4mr9vdm0004s0w9hdxl1tua","_id":"cl4mr9vdt000fs0w97nr5g5j1"},{"post_id":"cl4mr9vdk0003s0w92i011c6f","category_id":"cl4mr9vdr000as0w9er7i6i9c","_id":"cl4mr9vdt000is0w93vxxatr8"},{"post_id":"cl4mr9vdo0007s0w9g4fd91zy","category_id":"cl4mr9vds000ds0w9b4faa3qo","_id":"cl4mr9vdu000ls0w9ej4bdnsy"},{"post_id":"cl4mr9vdp0008s0w98s1ngzpm","category_id":"cl4mr9vdt000js0w9efc6b6x2","_id":"cl4mr9vdu000ns0w99l9z44qs"}],"PostTag":[{"post_id":"cl4mr9vdg0001s0w996o99a6j","tag_id":"cl4mr9vdn0005s0w9gf0t0ore","_id":"cl4mr9vdt000gs0w94xbsb4kq"},{"post_id":"cl4mr9vdg0001s0w996o99a6j","tag_id":"cl4mr9vdr000bs0w92nplbbgf","_id":"cl4mr9vdt000hs0w9boflcnak"},{"post_id":"cl4mr9vdk0003s0w92i011c6f","tag_id":"cl4mr9vds000es0w9bylw29k5","_id":"cl4mr9vdu000ps0w9cqmifn8m"},{"post_id":"cl4mr9vdk0003s0w92i011c6f","tag_id":"cl4mr9vdt000ks0w9e94i48pg","_id":"cl4mr9vdv000qs0w9gsmxbi47"},{"post_id":"cl4mr9vdk0003s0w92i011c6f","tag_id":"cl4mr9vdu000ms0w90pbyb3yk","_id":"cl4mr9vdv000ss0w91zw6ceug"},{"post_id":"cl4mr9vdo0007s0w9g4fd91zy","tag_id":"cl4mr9vdu000os0w9gdbcfol7","_id":"cl4mr9vdv000us0w94jpres5l"},{"post_id":"cl4mr9vdo0007s0w9g4fd91zy","tag_id":"cl4mr9vdv000rs0w910873ggx","_id":"cl4mr9vdv000vs0w95anug8qg"},{"post_id":"cl4mr9vdp0008s0w98s1ngzpm","tag_id":"cl4mr9vdv000ts0w98lk140nj","_id":"cl4mr9vdx000zs0w98hoc0r50"},{"post_id":"cl4mr9vdp0008s0w98s1ngzpm","tag_id":"cl4mr9vdw000ws0w96dmwgk01","_id":"cl4mr9vdy0010s0w9957sa048"},{"post_id":"cl4mr9vdp0008s0w98s1ngzpm","tag_id":"cl4mr9vdw000xs0w9040b216s","_id":"cl4mr9vdy0012s0w95dwl6xhl"},{"post_id":"cl4mr9vdq0009s0w9f2nmdps5","tag_id":"cl4mr9vds000es0w9bylw29k5","_id":"cl4mr9vdy0013s0w9a392c3wr"},{"post_id":"cl4mr9vdq0009s0w9f2nmdps5","tag_id":"cl4mr9vdy0011s0w9aa0v6g5w","_id":"cl4mr9vdz0014s0w94n48admo"}],"Tag":[{"name":"Moby Dick","_id":"cl4mr9vdn0005s0w9gf0t0ore"},{"name":"Reading","_id":"cl4mr9vdr000bs0w92nplbbgf"},{"name":"Poem","_id":"cl4mr9vds000es0w9bylw29k5"},{"name":"Literary criticism","_id":"cl4mr9vdt000ks0w9e94i48pg"},{"name":"Philip Larkin","_id":"cl4mr9vdu000ms0w90pbyb3yk"},{"name":"Ace","_id":"cl4mr9vdu000os0w9gdbcfol7"},{"name":"Taffy","_id":"cl4mr9vdv000rs0w910873ggx"},{"name":"ICSE 2022","_id":"cl4mr9vdv000ts0w98lk140nj"},{"name":"Code generation","_id":"cl4mr9vdw000ws0w96dmwgk01"},{"name":"Note","_id":"cl4mr9vdw000xs0w9040b216s"},{"name":"Self","_id":"cl4mr9vdy0011s0w9aa0v6g5w"}]}}